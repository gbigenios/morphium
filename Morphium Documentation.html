<!doctype html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Morphium Documentation</title>
</head>
<body>
<h1 id="morphium-documentation">Morphium Documentation</h1>
<div class="TOC">


    <ul>
        <li><a href="#morphium-documentation">Morphium Documentation</a>

            <ul>
                <li><a href="#what-is-morphium">What is <em>Morphium</em></a></li>
                <li><a href="#about-this-document">About this document</a></li>
                <li><a href="#using-morphium-as-a-messaging-system">Using <em>Morphium</em> as a messaging system</a>

                    <ul>
                        <li><a href="#why-morphium-messaging">why <em>Morphium</em> messaging</a></li>
                        <li><a href="#quick-start-messaging">Quick start Messaging</a></li>
                        <li><a href="#answering-messages">Answering messages</a></li>
                        <li><a href="#more-advanced-settings">more advanced settings</a>

                            <ul>
                                <li><a href="#custom-message-classes">Custom message classes</a></li>
                                <li><a href="#message-priorities">Message priorities</a></li>
                                <li><a href="#pausing-unpausing-of-messaging">Pausing / unpausing of messaging</a></li>
                                <li><a href="#multithreading-multimessage-processing">Multithreading / Multimessage
                                    processing</a></li>
                                <li><a href="#custom-messagequeue-name">Custom MessageQueue name</a></li>
                                <li><a href="#jms-support">JMS Support</a></li>
                            </ul>
                        </li>
                        <li><a href="#examples">Examples</a>

                            <ul>
                                <li><a href="#simple-producer-consumer-setup">Simple producer consumer setup:</a></li>
                                <li><a href="#direct-messages">Direct messages</a></li>
                                <li><a href="#exclusive-broadcast-messages">Exclusive Broadcast messages</a></li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li><a href="#inmemory-driver">InMemory Driver</a>

                    <ul>
                        <li><a href="#how-to-use-the-inmemory-driver">how to use the inMemory Driver</a></li>
                        <li><a href="#dumping-inmemory-data">Dumping InMemory data</a></li>
                    </ul>
                </li>
                <li><a href="#morphium-pojo-mapping"><em>Morphium</em> POJO Mapping</a>

                    <ul>
                        <li><a href="#ideas-and-design-criteria">Ideas and design criteria</a></li>
                        <li><a href="#concepts">Concepts</a></li>
                        <li><a href="#advantages-features">Advantages / Features</a>

                            <ul>
                                <li><a href="#pojo-mapping">POJO Mapping</a></li>
                                <li><a href="#declarative-caching">Declarative caching</a></li>
                                <li><a href="#cache-synchronization">cache synchronization</a></li>
                                <li><a href="#auto-versioning">Auto-Versioning</a></li>
                                <li><a href="#type-ids">Type IDs</a></li>
                                <li><a href="#sequences">Sequences</a></li>
                                <li><a href="#transparent-encryption-of-values">transparent encryption of values</a>
                                </li>
                                <li><a href="#binary-serialization">binary serialization</a></li>
                                <li><a href="#complex-data-structures">complex data structures</a></li>
                                <li><a href="#support-for-mapreduce">Support for MapReduce</a></li>
                                <li><a href="#automatic-retries-on-error">automatic retries on error</a></li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li><a href="#configuring-morphium-morphiumconfig">configuring <em>Morphium</em>:
                    <code>MorphiumConfig</code></a>

                    <ul>
                        <li><a href="#different-sources">Different sources</a>

                            <ul>
                                <li><a href="#json">Json</a></li>
                                <li><a href="#properties">Properties</a></li>
                                <li><a href="#java-code">Java-Code</a></li>
                            </ul>
                        </li>
                        <li><a href="#configuration-options">Configuration Options</a></li>
                        <li><a href="#authentication">authentication</a>

                            <ul>
                                <li><a href="#corresponding-mongod-config">corresponding MongoD Config</a></li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li><a href="#entity-definition">Entity Definition</a>

                    <ul>
                        <li><a href="#indexes">indexes</a>

                            <ul>
                                <li><a href="#text-indexes">Text indexes</a></li>
                            </ul>
                        </li>
                        <li><a href="#capped-collections">capped collections</a></li>
                    </ul>
                </li>
                <li><a href="#querying">Querying</a>

                    <ul>
                        <li><a href="#simple-queries">Simple queries</a></li>
                        <li><a href="#or-queries">Or Queries</a>

                            <ul>
                                <li><a href="#limitations">Limitations</a></li>
                            </ul>
                        </li>
                        <li><a href="#the-iterator">the Iterator</a></li>
                    </ul>
                </li>
                <li><a href="#storing">Storing</a>

                    <ul>
                        <li><a href="#names-of-entities-and-fields">Names of entities and fields</a>

                            <ul>
                                <li><a href="#camelcase-conversion">CamelCase conversion</a></li>
                                <li><a href="#using-the-full-qualified-classname">using the full qualified classname</a>
                                </li>
                                <li><a href="#specifying-a-collection-fieldname">Specifying a collection / fieldname</a>
                                </li>
                                <li><a href="#accessing-fields">Accessing fields</a></li>
                                <li><a href="#using-nameproviders">Using NameProviders</a></li>
                                <li><a href="#examples">examples</a></li>
                            </ul>
                        </li>
                        <li><a href="#automatic-values">Automatic values</a></li>
                    </ul>
                </li>
                <li><a href="#asynchronous-api">Asynchronous API</a>

                    <ul>
                        <li><a href="#difference-asynchronous-write-write-buffer">Difference asynchronous write / write
                            buffer</a></li>
                    </ul>
                </li>
                <li><a href="#validation-support">Validation support</a></li>
                <li><a href="#annotations">Annotations</a>

                    <ul>
                        <li><a href="#entity">Entity</a></li>
                        <li><a href="#embedded">Embedded</a></li>
                        <li><a href="#asyncwrites">AsyncWrites</a></li>
                        <li><a href="#nocache">NoCache</a></li>
                        <li><a href="#capped">Capped</a></li>
                        <li><a href="#collation">Collation</a></li>
                        <li><a href="#additionaldata">AdditionalData</a></li>
                        <li><a href="#aliases">Aliases</a></li>
                        <li><a href="#creationtime">CreationTime</a></li>
                        <li><a href="#lastaccess">LastAccess</a></li>
                        <li><a href="#lastchange">LastChange</a></li>
                        <li><a href="#defaultreadpreference">DefaultReadPreference</a></li>
                        <li><a href="#id">Id</a></li>
                        <li><a href="#index">Index</a></li>
                        <li><a href="#ignorefields">IgnoreFields</a></li>
                        <li><a href="#limittofields">LimitToFields</a></li>
                        <li><a href="#property">Property</a></li>
                        <li><a href="#readonly">ReadOnly</a></li>
                        <li><a href="#version">Version</a></li>
                        <li><a href="#reference">Reference</a>

                            <ul>
                                <li><a href="#lazy-loaded-references">Lazy Loaded references</a></li>
                            </ul>
                        </li>
                        <li><a href="#transient">Transient</a></li>
                        <li><a href="#cache">Cache</a></li>
                        <li><a href="#encrypted">Encrypted</a></li>
                        <li><a href="#useifnull">UseIfNull</a></li>
                        <li><a href="#lifecycle">LifeCycle</a></li>
                        <li><a href="#version">Version</a></li>
                        <li><a href="#writesafety">WriteSafety</a>

                            <ul>
                                <li><a href="#cluster-awareness">Cluster awareness</a></li>
                            </ul>
                        </li>
                        <li><a href="#annotation-inheritance">Annotation Inheritance</a></li>
                        <li><a href="#implementation">Implementation</a></li>
                    </ul>
                </li>
                <li><a href="#changestream-support">Changestream support</a>

                    <ul>
                        <li><a href="#partial-updating">partial updating</a></li>
                        <li><a href="#bulkrequest-support">BulkRequest support</a></li>
                        <li><a href="#transaction-support">Transaction support</a></li>
                    </ul>
                </li>
                <li><a href="#listeners-in-morphium">Listeners in <em>Morphium</em></a>

                    <ul>
                        <li><a href="#replicasetstatuslistener">ReplicasetStatusListener</a></li>
                    </ul>
                </li>
                <li><a href="#cachelistener">CacheListener</a>

                    <ul>
                        <li><a href="#cachesynclistener">CacheSyncListener</a></li>
                        <li><a href="#changestreamlistener">ChangeStreamListener</a></li>
                        <li><a href="#messagelistener">MessageListener</a></li>
                        <li><a href="#morphiumstoragelistener">MorphiumStorageListener</a></li>
                        <li><a href="#oploglistener">OplogListener</a></li>
                        <li><a href="#profiling-listener">Profiling Listener</a></li>
                    </ul>
                </li>
                <li><a href="#the-aggregation-framework">The Aggregation Framework</a>

                    <ul>
                        <li><a href="#aggregation-expressions">Aggregation Expressions</a></li>
                    </ul>
                </li>
                <li><a href="#additional-information-sources">Additional information sources</a></li>
                <li><a href="#code-examples">Code Examples</a>

                    <ul>
                        <li><a href="#cache-synchronization">Cache Synchronization</a></li>
                        <li><a href="#geo-spacial-search">Geo Spacial Search</a></li>
                        <li><a href="#iterator">Iterator</a></li>
                        <li><a href="#asynchronous-read">Asynchronous Read</a></li>
                        <li><a href="#asynchronous-write">Asynchronous Write</a></li>
                    </ul>
                </li>
                <li><a href="#disclaimer">Disclaimer</a></li>
            </ul>
        </li>
    </ul>
</div>

<h2 id="what-is-morphium">What is <em>Morphium</em></h2>

<p><em>Morphium</em> started as a feature rich access layer and POJO mapper for MongoDB in java. It was built with speed
    and flexibility in mind. So it supported cluster aware caching out of the box, lazy loading references and much
    more. The POJO Mapping is the <em>core</em> of <em>Morphium</em>, all other features were built around that. It
    makes accessing MongoDB easy, supports all great features of MongoDB and adds some more.</p>

<p>But with time, the MongoDB based messaging became one of the most popular features in <em>Morphium</em>. It is fast,
    reliable, customisable and stable. </p>

<h2 id="about-this-document">About this document</h2>

<p>This document is a documentation for <em>Morphium</em> in the current (4.2) version. It would be best, if you had a
    basic understanding of MongoDB and a good knowledge on <em>Morphium</em>. If you want to know about MongoDB's
    features, that <em>Morphium</em> implements here, have a look at the official MongoDB pages and the documentation
    there.</p>

<p>This documentation covers all features <em>Morphium</em> has to offer.</p>

<p>Later in this document there are chapters about the POJO mapping, querying data and using the aggregation
    framework.</p>

<p>Also a chapter about the InMemory driver, which is quite useful for testing. But let's start with the mess'aging</p>

<p>subsystem first.</p>

<h2 id="using-morphium-as-a-messaging-system">Using <em>Morphium</em> as a messaging system</h2>

<p><em>Morphium</em> itself is simple to use, easy to customise to your needs and was built for high performance and
    scalability. The messaging system is no different. It relies on the <code>watch</code> functionality, that MongoDB
    offers since V3.6 (you can also use messaging with older versions of MongoDB, but it will result in polling for new
    messages). With that feature, the messages are <em>pushed</em> to all listeners. This makes it a very efficient
    messaging system based on MongoDB.</p>

<h3 id="why-morphium-messaging">why <em>Morphium</em> messaging</h3>

<p>There is a ton of messaging solutions out there. All of them have their advantages and offer lots of features. But
    only few of them offer the things that <em>Morphium</em> has:</p>

<ul>
    <li>the message queue can easily be inspected and you can use mongo search queries to find the messages you are
        looking for<sup><a class="footnote" href="#fn1-7368" id="fnr1-7368" title="see footnote">1</a></sup></li>
    <li>the message queue can be altered (update single messages with ease, delete messages or just <em>add</em> new
        messages)
    </li>
    <li>Possibility to broadcast messages, that are only processed by one client max (Exclusive Messages). With V4.2 of
        <em>Morphium</em> this also works with a group of recipients.
    </li>
    <li>Messaging is multithreaded and thread safe</li>
    <li>pausing and unpausing of message processing without data loss</li>
    <li><em>Morphium</em> messaging picks up all pending messages on startup - no data loss.</li>
    <li>no need to install additional servers or provide separate infrastructure. Just use your MongoDB you likely
        already have in place.
    </li>
</ul>

<p>There are people out there using <em>Morphium</em> and its messaging for production grade development. For example <a
        href="https://www.genios.de">Genios.de</a> uses Morphium messaging to power a microservice architecture with an
    enterprise message bus.</p>

<h3 id="quick-start-messaging">Quick start Messaging</h3>

<pre><code class="java">Morphium m=new Morphium();
Messaging messaging=new Messaging(m);
 
messaging.addMessageListener((messaging, msg) -&gt; {
            log.info(&quot;Got message!&quot;);
            return null;  //not sending an answer
        });
</code></pre>

<p>This is a simple example of how to implement a message consumer. This consumer listens to <em>all</em> incoming
    messages, regardless of name. </p>

<p>Messages do have some fields, that you might want to use for your purpose. But you can create your own message type
    as well (see below). the Msg-Class defines those properties:</p>

<ul>
    <li><code>name</code> the name of the Message - you can define listeners only listening to messages of a specific
        name using <code>addListenerForMessageNamed</code>. Similar to a <em>topic</em> in other messaging systems
    </li>
    <li><code>msg</code>: String message</li>
    <li><code>value</code>: well - a String value</li>
    <li><code>mapValue</code>: for more complex use cases where you need to send more information</li>
    <li><code>additional</code>: list value - used for more complex use cases</li>
    <li>all messages do store some values for the processing algorithm, like <code>processed_by</code>, <code>in_answer_to</code>,
        <code>timestamp</code> etc.
    </li>
</ul>

<p>So if you want to send a Message, that is also simple:</p>

<pre><code class="java">messaging.queueMessage(new Msg(&quot;name&quot;,&quot;A message&quot;,&quot;the value&quot;);
</code></pre>

<p>queueMessage is running asynchronously, which means, that the message is <em>not</em> directly stored. If you need
    more speed and shorter reaction time, you should use <code>sendMessage</code> instead (directly storing message to
    mongo).</p>

<h3 id="answering-messages">Answering messages</h3>

<p><em>Morphium</em> is able to answer any message for you. Your listener implementation only needs to return an
    instance of</p>

<p>the <code>Msg</code>-Class. This will then be sent back to the sender as an answer.</p>

<p>When sending a message, you also may wait for the incoming answer. The Messaging class offers a method for that
    purpose:</p>

<pre><code>//new messaging instance with polling frequency of 100ms, not multithreaded
//polling only used in case of non-Replicaset connections and in some
//cases like unpausing to find pending messages

    Messaging sender = new Messaging(_Morphium_, 100, false);
    sender.start();

    gotMessage1 = false;
    gotMessage2 = false;
    gotMessage3 = false;
    gotMessage4 = false;

    Messaging m1 = new Messaging(_Morphium_, 100, false);
    m1.addMessageListener((msg, m) -&gt; {
        gotMessage1 = true;
        return new Msg(m.getName(), &quot;got message&quot;, &quot;value&quot;, 5000);
    });

    m1.start();
    Thread.sleep(2500);

    Msg answer = sender.sendAndAwaitFirstAnswer(new Msg(&quot;test&quot;, &quot;Sender&quot;, &quot;sent&quot;, 15000), 15000);
    assertNotNull(answer);;
    assert (answer.getName().equals(&quot;test&quot;));
    assertNotNull(answer.getInAnswerTo());;
    assertNotNull(answer.getRecipient());;
    assert (answer.getMsg().equals(&quot;got message&quot;));
    m1.terminate();
    sender.terminate();
</code></pre>

<p>As the whole communication is asynchronous, you will have to specify a timeout after wich the wait for answer will be
    aborted with an exception. And, there might be more than one answers to the same message, hence you will only get
    the first one.</p>

<p>in the above example, the timeout for the answer is set to 15s (and the TTL for messages also).</p>

<h3 id="more-advanced-settings">more advanced settings</h3>

<h4 id="custom-message-classes">Custom message classes</h4>

<p>As mentioned above, you can define your own Message-Class to be send back and forth. This class just needs to extend
    the standard <code>Msg</code>-Class. When adding a listener to messaging, you have the option to also use generics
    to specify the Msg-Type you want to use. </p>

<h4 id="message-priorities">Message priorities</h4>

<p>Every message does have a priority field. That is used for giving queued messages precedence over others. The
    priority could be changed <em>after</em> a message is queued directly in MongoDB (or using <em>Morphium</em>).</p>

<p>But as the messaging is built on pushing of messages, when is the priority field used? Several cases:</p>

<ul>
    <li>when starting up messaging. When starting Messaging, the system does look for pending messages in the queue,
        highes prio is used first
    </li>
    <li>when unpausing a messaging instance, it will look for any messages in the queue and will process them according
        to their priority.
    </li>
</ul>

<h4 id="pausing-unpausing-of-messaging">Pausing / unpausing of messaging</h4>

<p>In some cases it might be necessary to pause message processing for a time. That might be the case, if the message is
    triggering some long running task or so. If so, it would be good not to process any additional messages (at least of
    that type).</p>

<p>You can call <code>messaging.pauseProcessingOfMessagesNamed</code> to <em>not</em> process any more messages of a
    certain type.</p>

<p><em>Attention</em>: if you have long running tasks triggered by messages, you should pause processing in the
    onMessage method and unpause it when finished.</p>

<h4 id="multithreading-multimessage-processing">Multithreading / Multimessage processing</h4>

<p>When instantiating Messaging, you can specify two booleans:</p>

<ul>
    <li><p>multithreading: if true, every incoming message will be processed in an own thread (Executor - see
        MorphiumConfig</p>
        below). That means, several messages can be processed in parallel
    </li>
    <li><p>processMultiple: this setting is only important in case of startup or unpausing. If true, messaging will lock
        all</p>

        <p>messages available for this listener and process them one by one (or in parallel if multithreading is
            enabled). These</p>
        settings are influenced by other settings:
    </li>
    <li><p><code>messagingWindowSize</code> in MorphiumConfig or as constructor parameter / setter in Messaging: this
        defines how many</p>

        <p>messages are marked for processing at once. Those might be processed in parallel (depending whether <code>processMultiple</code>
        </p>
        is true, and the executor configuration, how many threads can be run in parallel)
    </li>
    <li><code>useChangeStream</code> in Messaging. Usually messaging determines by the cluster status, whether or not to
        use the changestream or not. If in a cluster, use it, if not use polling. But if you explicitly want to use
        polling, you can set this value to <code>false</code>. The advantage here might be, that the messages are
        processed by priority with every poll. This might be useful depending on your usecase. If this is set to false
        (or you are connected to an single instance), the <code>pause</code> configuration option (aka polling
        frequency) in Messaging will determine how fast your messages can be consumed. <strong>Attention</strong> high
        polling frequency (a low <code>pause</code> value), will increase the load on MongoDB.
    </li>
    <li><code>ThreadPoolMessagingCoreSize</code> in MorphiumConfig: If you define messaging to be multithreaded it will
        spawn a new thread with each incoming message. this is the core size of the corresponding thread pool. If your
        messaging instance is not configured for multithreading, this setting is not used.
    </li>
    <li><code>ThreadPoolMessagingMaxSize</code>: max size of the thread pool. similar to above.</li>
    <li><p><code>ThreadPoolMessagingKeepAliveTime</code>: time of threads to live in ms</p>
        some examples to clarify that:
    </li>
    <li>your messaging instance is configured for multithreaded processing, multiple processing, having a <code>windowSize</code>
        of 100 and a <code>ThreadPoolMessagingMaxSize</code> of 10, then there will be 100 messages in queue marked for
        being processed by this specific messaging instance, but only 10 will be processed in parallel.
    </li>
    <li>multithreaded processing is false, then the <code>windowSize</code> determines how many messages are marked for
        being processed, but are only processed one by one
    </li>
    <li>multithreaded processing and multiple processing is false, then only one message is marked for being processed
        at a time. As soon as this processing is finished, the next message is being taken.
    </li>
    <li>having <code>multithreaded</code> set to true and <code>processMultiple</code> set to false would result in
        running each message processing in one separate thread, but only one at a time. This is very similar to having
        <code>multithreaded</code> and <code>process multiple</code> both set to false.
    </li>
</ul>

<h4 id="custom-messagequeue-name">Custom MessageQueue name</h4>

<p>When creating a Messaging instance, you can set a collection name to use. This could be compared to having a separate
    message queue in the system. Messages sent to one queue are not being registered by another.</p>

<h4 id="jms-support">JMS Support</h4>

<p><em>Morphium</em> messaging also implements the standard JMS-API to a certain extend and can be used this way. Please
    keep in mind that JMS does not support most of the features, <em>Morphium</em> messaging offers, and that the JMS
    implementation does not cover 100% of the JMS API yet:</p>

<pre><code class="java">@Test
    public void basicSendReceiveTest() throws Exception {
        JMSConnectionFactory factory = new JMSConnectionFactory(morphium);
        JMSContext ctx1 = factory.createContext();
        JMSContext ctx2 = factory.createContext();

        JMSProducer pr1 = ctx1.createProducer();
        Topic dest = new JMSTopic(&quot;test1&quot;);

        JMSConsumer con = ctx2.createConsumer(dest);
        con.setMessageListener(message -&gt; log.info(&quot;Got Message!&quot;));
        Thread.sleep(1000);
        pr1.send(dest, &quot;A test&quot;);

        ctx1.close();
        ctx2.close();
    }
    
     @Test
    public void synchronousSendRecieveTest() throws Exception {
        JMSConnectionFactory factory = new JMSConnectionFactory(morphium);
        JMSContext ctx1 = factory.createContext();
        JMSContext ctx2 = factory.createContext();

        JMSProducer pr1 = ctx1.createProducer();
        Topic dest = new JMSTopic(&quot;test1&quot;);
        JMSConsumer con = ctx2.createConsumer(dest);

        final Map&lt;String, Object&gt; exchange = new ConcurrentHashMap&lt;&gt;();
        Thread senderThread = new Thread(() -&gt; {
            JMSTextMessage message = new JMSTextMessage();
            try {
                message.setText(&quot;Test&quot;);
            } catch (JMSException e) {
                e.printStackTrace();
            }
            pr1.send(dest, message);
            log.info(&quot;Sent out message&quot;);
            exchange.put(&quot;sent&quot;, true);
        });
        Thread receiverThread = new Thread(() -&gt; {
            log.info(&quot;Receiving...&quot;);
            Message msg = con.receive();
            log.info(&quot;Got incoming message&quot;);
            exchange.put(&quot;received&quot;, true);
        });
        receiverThread.start();
        senderThread.start();
        Thread.sleep(5000);
        assertNotNull(exchange.get(&quot;sent&quot;));;
        assertNotNull(exchange.get(&quot;received&quot;));;
    }
</code></pre>

<p><strong>Caveats:</strong></p>

<p>The JMS Implementation uses the answering mechanism for acknowledging incoming messages. This makes JMS more or less
    half as fast as the direct usage of <em>Morphium</em> messaging. </p>

<p>Also, the implementation is very basic at the moment. A lot of methods lack implementation<sup><a class="footnote"
                                                                                                     href="#fn2-7368"
                                                                                                     id="fnr2-7368"
                                                                                                     title="see footnote">2</a></sup>.
    If you notice some missing functionality, just open an issue at <a href="https://github.com/sboesebeck/morphium">github</a>.
</p>

<p>Because of the JMS Implementation being very basic at the moment, it should not be considered production ready!</p>

<h3 id="examples">Examples</h3>

<h4 id="simple-producer-consumer-setup">Simple producer consumer setup:</h4>

<pre><code class="java">Morphium m=new Morphium(config);
// create messaging instance with default settings, meaning
// no multithreading, windowSize of 100, processMultiple false
Messaging producer=new Messaging(m);

producer.queueMessage(new Msg(&quot;name&quot;,&quot;a message&quot;,&quot;a value&quot;));

the receiver needs to connect to the same mongo and the same database:

Morphium m=new Morphium(config);
Messaging consumer=new Messaging(m);
consumer.start(); //needed for receiving messages

consumer.addMessageListener((messaging, msg) -&gt; {
         //Incoming message 
         System.out.println(&quot;Got a message of name &quot;+msg.getName());
         return null; //no answer to send back
        });
</code></pre>

<p>you can also register listeners only for specific messages:consumer.start(); //needed for receiving messages</p>

<pre><code class="java">consumer.addListenerForMessageNamed(&quot;name&quot;,(messaging, msg) -&gt; {
       //Incoming message, is always named &quot;name&quot;
         System.out.println(&quot;Got value: &quot;+msg.getValue());
         Msg answer=new Msg(msg.getName(),&quot;answer&quot;,&quot;the answerValue&quot;);
         return answer; //no answer to send back
        });
</code></pre>

<p><strong>Attention</strong>: the producer will only be able to process incoming messages, if <code>start()</code> was
    called!</p>

<p>The message sent there was a broadcast message. All registered listeners will receive that message and will process
    it!</p>

<h4 id="direct-messages">Direct messages</h4>

<p>In order to send a message directly to a specific messaging instance, you need to get the unique ID of it. This id is
    add as sender to any message. </p>

<pre><code>Msg m=new Msg(&quot;Name&quot;,&quot;Message&quot;,&quot;value&quot;);
m.addRecipient(messaging1.getId());
//you could add more recipients if necessary
</code></pre>

<p><em>Background</em>: This is used to send answers back to the sender. If you return a message instance in <code>onMessage</code>,
    this message will be sent directly back to the sender.</p>

<p>You can add as many recipients as needed, if no recipient is defined, the message by default is sent to all
    listeners.</p>

<h4 id="exclusive-broadcast-messages">Exclusive Broadcast messages</h4>

<p>Broadcast messages are fine for informing all listeners about something. But for some more complex scenarios, you
    would need a way to queue a message, and have only one listener process it - no matter which one (load
    balancing?)</p>

<p><em>Morphium</em> supports this kind of messages, it is called &quot;exclusive broadcast&quot;. This way, you can
    easily scale up by just adding listener instances.</p>

<p>Sending a exclusive broadcast message is simple:</p>

<pre><code>    Msg m=new Message(&quot;exclusive&quot;,&quot;The message&quot;,&quot;and value&quot;);
    m.setExclusive(true);
    messaging.queueMessage(m);
</code></pre>

<p>The listener only need to implement the standard <code>onMessage</code>-Method to get this message. Due to some
    sophisticated locking of messages, <em>Morphium</em> makes this message exclusive - which means, it is only
    processed once!</p>

<p>Since <em>Morphium</em> V4.2 it is also possible to send an exclusive message to certain recipients<sup><a
        class="footnote" href="#fn3-7368" id="fnr3-7368" title="see footnote">3</a></sup>. </p>

<p>The behaviour is the same: the message will only be processed by <em>one</em> of the specified recipients, whereas it
    will be processed by <em>all</em> recipients, if not exclusive.</p>

<h2 id="inmemory-driver">InMemory Driver</h2>

<p>One main purpose of the <code>InMemoryDriver</code> is to be able to do testing without having a MongoDB installed.
    The InMemoryDriver adds the opportunity to let all MongoDB-code run in Memory, with a couple of exceptions</p>

<ul>
    <li>unfortunately, the InMemoryDriver cannot do aggregations. It will throw an Exception, when trying Aggregations
        with this driver
    </li>
    <li>the inMemoryDriver is also not capable to return cluster information, run mongodb commands</li>
    <li>it does not support spacial indexes or queries</li>
</ul>

<p>If you want to mock those things in testing, you need to:</p>

<ol>
    <li>create a subclass of the inMemoryDriver</li>
    <li>override the corresponding method, for example <code>aggregate()</code> for aggregation and return the properly
        mocked data
    </li>
    <li>set the driver back to default in order to have it work</li>
</ol>

<pre><code class="java">        @Test
        public void mockAggregation() throws Exception{
            MorphiumDriver original=morphium.getDriver();
            morphium.setDriver(new InMemoryDriver(){
                @Override
                public List&lt;Map&lt;String, Object&gt;&gt; aggregate(String db, String collection, List&lt;Map&lt;String, Object&gt;&gt; pipeline, boolean explain, boolean allowDiskUse, Collation collation, ReadPreference readPreference) throws MorphiumDriverException {
                    return Arrays.asList(UtilsMap.of(&quot;MockedData&quot;,123.0d));
                }
            });
    
        Aggregator&lt;UncachedObject, Map&gt; agg = morphium.createAggregator(UncachedObject.class, Map.class);        
        //... 
        assert(agg.aggregate().get(0).get(&quot;MockedData&quot;).equals(123.0d)); //checking mocked data
        morphium.getDriver().close(); 
        morphium.setDriver(original);
       }
</code></pre>

<h3 id="how-to-use-the-inmemory-driver">how to use the inMemory Driver</h3>

<p>you just need to set the Driver properly in your <em>Morphium</em> configuration. </p>

<pre><code>    MorphiumConfig cfg = new MorphiumConfig();
    cfg.addHostToSeed(&quot;inMem&quot;);
    cfg.setDatabase(&quot;test&quot;);
    cfg.setDriverClass(InMemoryDriver.class.getName());
    cfg.setReplicasetMonitoring(false);
    morphium = new Morphium(cfg);
</code></pre>

<p>Of course, the <em>InMemDriver</em> does not need hosts to connect to, but for compatibility reasons, you need to add
    at least one host (although it will be ignored).</p>

<p>You can also set the Driver in the settings, e.g. in properties:</p>

<pre><code>morphium.driverClass = &quot;de.caluga.morphium.driver.inmem.InMemoryDriver&quot;
</code></pre>

<p>After that initialisation you can use this <em>Morphium</em> instance as always, except that it will &quot;persist&quot;
    data only in Memory.</p>

<h3 id="dumping-inmemory-data">Dumping InMemory data</h3>

<p>As in memory storage is by definition not lasting, it might be a good idea to store your data onto disk for later
    use. The InMemoryDriver does support that:</p>

<pre><code class="java"> @Test
public void driverDumpTest() throws Exception {
    for (int i = 0; i &lt; 100; i++) {
        UncachedObject e = new UncachedObject();
        e.setCounter(i);
        e.setValue(&quot;value&quot; + i);
        e.setIntData(new int[]{i, i + 1, i + 2});
        e.setDval(42.00001);
        e.setBinaryData(new byte[]{1, 2, 3, 4, 5});
        morphium.store(e);

        ComplexObject o = new ComplexObject();
        o.setEinText(&quot;A text &quot; + i);
        o.setEmbed(new EmbeddedObject(&quot;emb&quot;, &quot;v1&quot;, System.currentTimeMillis()));
        o.setRef(e);
        morphium.store(o);


    }

    ByteArrayOutputStream bout = new ByteArrayOutputStream();

    InMemoryDriver driver = (InMemoryDriver) morphium.getDriver();
    driver.dump(morphium, morphium.getDriver().listDatabases().get(0), bout);
    log.info(&quot;database dump is &quot; + bout.size());

    driver.close();
    driver.connect();
    driver.restore(new ByteArrayInputStream(bout.toByteArray()));
    assert (morphium.createQueryFor(UncachedObject.class).countAll() == 100);
    assert (morphium.createQueryFor(ComplexObject.class).countAll() == 100);

    for (ComplexObject co : morphium.createQueryFor(ComplexObject.class).asList()) {
        assertNotNull(co.getEinText());;
        assertNotNull(co.getRef());;
    }
}
</code></pre>

<p>In this example, data is stored to a binary stream, which could also be stored to disk somewhere.</p>

<p>But you can also create a dump in <em>JSON</em> format, which makes it easier to edit and maybe to create from
    scratch:</p>

<pre><code class="java">
@Test
public void jsonDumpTest() throws Exception {

    MorphiumTypeMapper&lt;ObjectId&gt; mapper = new MorphiumTypeMapper&lt;ObjectId&gt;() {
        @Override
        public Object marshall(ObjectId o) {
            Map&lt;String, String&gt; m = new HashMap&lt;&gt;();
            m.put(&quot;value&quot;, o.toHexString());
            m.put(&quot;class_name&quot;, o.getClass().getName());
            return m;

        }

        @Override
        public ObjectId unmarshall(Object d) {
            return new ObjectId(((Map) d).get(&quot;value&quot;).toString());
        }
    };
    morphium.getMapper().registerCustomMapperFor(ObjectId.class, mapper);
    for (int i = 0; i &lt; 10; i++) {
        UncachedObject e = new UncachedObject();
        e.setCounter(i);
        e.setValue(&quot;value&quot; + i);
        morphium.store(e);
    }
    ExportContainer cnt = new ExportContainer();
    cnt.created = System.currentTimeMillis();

    cnt.data = ((InMemoryDriver) morphium.getDriver()).getDatabase(morphium.getDriver().listDatabases().get(0));

    Map&lt;String, Object&gt; s = morphium.getMapper().serialize(cnt);
    System.out.println(Utils.toJsonString(s));

    morphium.dropCollection(UncachedObject.class);
    ExportContainer ex = morphium.getMapper().deserialize(ExportContainer.class, Utils.toJsonString(s));
    assertNotNull(ex);;
    ((InMemoryDriver) morphium.getDriver()).setDatabase(morphium.getDriver().listDatabases().get(0), ex.data);

    List&lt;UncachedObject&gt; result = morphium.createQueryFor(UncachedObject.class).asList();
    assert (result.size() == 10);
    assert (result.get(1).getCounter() == 1);
}


@Entity
public static class ExportContainer {
    @Id
    public Long created;
    public Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; data;
}
</code></pre>

<p>The JSON output of this little dump looks like this:</p>

<pre><code class="json">{
   &quot;_id&quot; : 1599853076411,
   &quot;data&quot; : {
      &quot;uncached_object_0&quot; : [
         {
            &quot;_id&quot; : {
               &quot;class_name&quot; : &quot;org.bson.types.ObjectId&quot;,
               &quot;value&quot; : &quot;5f5bd214f8fd82e792ef3b51&quot;
            },
            &quot;counter&quot; : 0,
            &quot;dval&quot; : 0,
            &quot;value&quot; : &quot;value0&quot;
         },
         {
            &quot;_id&quot; : {
               &quot;class_name&quot; : &quot;org.bson.types.ObjectId&quot;,
               &quot;value&quot; : &quot;5f5bd214f8fd82e792ef3b53&quot;
            },
            &quot;counter&quot; : 1,
            &quot;dval&quot; : 0,
            &quot;value&quot; : &quot;value1&quot;
         },
         {
            &quot;_id&quot; : {
               &quot;class_name&quot; : &quot;org.bson.types.ObjectId&quot;,
               &quot;value&quot; : &quot;5f5bd214f8fd82e792ef3b55&quot;
            },
            &quot;counter&quot; : 2,
            &quot;dval&quot; : 0,
            &quot;value&quot; : &quot;value2&quot;
         },
         {
            &quot;_id&quot; : {
               &quot;class_name&quot; : &quot;org.bson.types.ObjectId&quot;,
               &quot;value&quot; : &quot;5f5bd214f8fd82e792ef3b57&quot;
            },
            &quot;counter&quot; : 3,
            &quot;dval&quot; : 0,
            &quot;value&quot; : &quot;value3&quot;
         },
         {
            &quot;_id&quot; : {
               &quot;class_name&quot; : &quot;org.bson.types.ObjectId&quot;,
               &quot;value&quot; : &quot;5f5bd214f8fd82e792ef3b59&quot;
            },
            &quot;counter&quot; : 4,
            &quot;dval&quot; : 0,
            &quot;value&quot; : &quot;value4&quot;
         },
         {
            &quot;_id&quot; : {
               &quot;class_name&quot; : &quot;org.bson.types.ObjectId&quot;,
               &quot;value&quot; : &quot;5f5bd214f8fd82e792ef3b5b&quot;
            },
            &quot;counter&quot; : 5,
            &quot;dval&quot; : 0,
            &quot;value&quot; : &quot;value5&quot;
         },
         {
            &quot;_id&quot; : {
               &quot;class_name&quot; : &quot;org.bson.types.ObjectId&quot;,
               &quot;value&quot; : &quot;5f5bd214f8fd82e792ef3b5d&quot;
            },
            &quot;counter&quot; : 6,
            &quot;dval&quot; : 0,
            &quot;value&quot; : &quot;value6&quot;
         },
         {
            &quot;_id&quot; : {
               &quot;class_name&quot; : &quot;org.bson.types.ObjectId&quot;,
               &quot;value&quot; : &quot;5f5bd214f8fd82e792ef3b5f&quot;
            },
            &quot;counter&quot; : 7,
            &quot;dval&quot; : 0,
            &quot;value&quot; : &quot;value7&quot;
         },
         {
            &quot;_id&quot; : {
               &quot;class_name&quot; : &quot;org.bson.types.ObjectId&quot;,
               &quot;value&quot; : &quot;5f5bd214f8fd82e792ef3b61&quot;
            },
            &quot;counter&quot; : 8,
            &quot;dval&quot; : 0,
            &quot;value&quot; : &quot;value8&quot;
         },
         {
            &quot;_id&quot; : {
               &quot;class_name&quot; : &quot;org.bson.types.ObjectId&quot;,
               &quot;value&quot; : &quot;5f5bd214f8fd82e792ef3b63&quot;
            },
            &quot;counter&quot; : 9,
            &quot;dval&quot; : 0,
            &quot;value&quot; : &quot;value9&quot;
         }
      ]
   }
}
</code></pre>

<h2 id="morphium-pojo-mapping"><em>Morphium</em> POJO Mapping</h2>

<h3 id="ideas-and-design-criteria">Ideas and design criteria</h3>

<p>In the early days of MongoDB there were not many POJO mapping libraries available. One was called <em>morphia</em>.
    Unfortunately we had a lot of problems adapting this to our needs. </p>

<p>Hence we built <strong>Morphium</strong> and we named it similar to <em>morphia</em> to show where the initial idea
    came from.</p>

<p><em>Morphium</em> is built with flexibility, thread safety, performance and cluster awareness in mind. </p>

<ul>
    <li><p>flexibility: it is possible to exchange most of the internal implementations of <em>Morphium</em>. You could
        have your own</p>
        Driver class for connecting to MongoDB or have a custom implementation for the query processing.
    </li>
    <li>thread safety: all aspects of <em>Morphium</em> were tested multithreaded so that it can be used in production
    </li>
    <li><p>performance: one of the main goals of <em>Morphium</em> was to improve performance. The Object Mapping in use
        is a custom</p>

        <p>implementation that was built especially for <em>Morphium</em>, is very fast and to improve speed even
            further, caching is</p>
        part of the core features of <em>Morphium</em></li>
    <li><p>cluster awareness: this is essential nowadays for high availability or just mere speed. _Morphium_s caches
        are all</p>
        cluster aware which means you will not end up with dirty reads in a clustered environment when using <em>Morphium</em>
    </li>
    <li><p>independent from mongoDB Driver: <em>Morphium</em> does not have a direct dependency on the mongoDB java
        driver, instead it</p>

        <p>considers it to be provided. This means, you can have a different version of the driver in use than the one
            <em>Morphium</em></p>

        <p>was last tested with (you do not need the latest and grates, usually it is backward compatible). In addition
            to</p>

        <p>that, <em>Morphium</em> does not directly use MongoDB or BSON classes but offers its own implementation. For
            example</p>
        the <code>MorphiumId</code>, wich is a drop in replacement for <code>ObjectId</code>.
    </li>
    <li>Clear Design Idea: code for reading from MongoDB is encapsulated in <code>Query</code> or <code>QueryImpl</code>
        respectively. All code for writing to MongoDB is encapsulated in <code>Morphium</code> itself. For convenience
        there are some calls from one to another, but the actual code is located as stated.
    </li>
</ul>

<h3 id="concepts">Concepts</h3>

<p><em><em>Morphium</em></em> is built to be very flexible and can be used in almost any environment. So the
    architecture needs to be flexible and sustainable at the same time. Hence it's possible to use your own
    implementation for the cache if you want to.</p>

<p>There are four major components of <em><em>Morphium</em></em>:</p>

<ol>
    <li>the <em><em>Morphium</em></em> Instance: This is you main entry point for interaction with Mongo. Here you
        create Queries and you write data to mongo. All writes will then be forwarded to the configured Writer
        implementation, all reads are handled by the Query-Object
    </li>
    <li>Query-Object: you need a query object to do reads from mongo. This is usually created by using <code>_Morphium_.createQueryFor(Class&lt;T&gt;
        cls)</code>. With a Query, you can easily get data from database or have some things changed (update) and alike.
    </li>
    <li>the Cache: For every request that should be sent to mongo, <em><em>Morphium</em></em> checks first, whether this
        collection is to be cached and if there is already a result being stored for the corresponding request.
    </li>
    <li>The Writers: there are 3 different types of writers in <em><em>Morphium</em></em>: The Default Writer (<code>_Morphium_Writer</code>)
        - writes directly to database, waiting for the response, the BufferedWriter (<code>BufferedWriter</code>) - does
        not write directly. All writes are stored in a buffer which is then processed as a bulk. The last type of writer
        ist the asynchronous writer (<code>AsyncWriter</code>) which is similar to the buffered one, but starts writing
        immediately - only asynchronous. <em><em>Morphium</em></em> decides which writer to use depending on the
        configuration and the annotations of the given Entities. But you can <em>always</em> use asynchronous calls just
        by adding a<code>AsyncCallback</code> implementation to your request.
    </li>
</ol>

<p>Simple rule when using <em><em>Morphium</em></em>: You want to read -&gt; Use the Query-Object. You want to write:
    Use the <em><em>Morphium</em></em> Object.</p>

<p>There are some additional features built upon this architecture:</p>

<ul>
    <li>messaging: <em><em>Morphium</em></em> has its own production grade messaging system. Its has a lot of features,
        that are unique for a messaging system.
    </li>
    <li>cache synchronization: Synchronize caches in a clustered environment. Uses messaging.</li>
    <li>custom mappers - you can tell <em><em>Morphium</em></em> how to map a certain type from and to MongoDB. For
        example there is a &quot;custom&quot; mapper implementation for mapping <code>BigInteger</code> instances to
        MongoDB.
    </li>
    <li>every one of those implementations can be changed: it is possible to set the class name for the <code>BufferedWriter</code>
        to a custom built one (in <code>MorphiumConfig</code>). Also you could replace the object mapper with your own
        implementation by implementing the <code>ObjectMapper</code> interface and telling <em>Morphium</em> which class
        to use instead. In short, these things can be changed in <em>Morphium</em> / MorphiumConfig:

        <ul>
            <li>MorphiumCache</li>
            <li>ObjectMapper</li>
            <li>Query</li>
            <li>Field</li>
            <li>QueryFactory</li>
            <li>Aggregator</li>
            <li>AggregatorFactory</li>
            <li>MorphiumDriver (&gt; V3.0, for connecting to MongoDB or any other data source if you want to. For
                example, there is an In-Memory-Driver you might want to use for testing. As an example, there is also an
                InfluxDB-Driver available.)
            </li>
        </ul>
    </li>
    <li>Object Mapping from and to Strings (using the object mapper) and JSON.</li>
    <li>full support for the Aggregation Framework</li>
    <li>Transaction support (for supporting MongoDB versions)</li>
    <li>Automatic encryption of fields (this is a re-implementation of the MongoDB enterprise feature in pure java -
        works declarative)
    </li>
</ul>

<h3 id="advantages-features">Advantages / Features</h3>

<h4 id="pojo-mapping">POJO Mapping</h4>

<p><em>Morphium</em> is capable of mapping standard Java objects (POJOs - plain old java objects) to MongoDB documents
    and back. This should make it possible to seemlessly integrate MongoDB into your application.</p>

<h4 id="declarative-caching">Declarative caching</h4>

<p>When working with databases - not only NoSQL ones - you need to consider caching. <em>Morphium</em> integrates
    transparent</p>

<p>declarative caching by entity to your application, if needed. Just define your caching needs in the
    <code>@Cache</code> annotation.</p>

<p>The cache uses any JavaCache compatible cache implementation (like EHCache), but provides an own implementation
    if</p>

<p>nothing is specified otherwise.</p>

<p>There are two kinds of caches: read cache and write cache.</p>

<p><strong>Write cache</strong>:</p>

<p>The WriteCache is just a buffer, where all things to write will be stored and eventually stored to database. This is
    done by adding the Annotation <code>@WriteBuffer</code> to the class:</p>

<pre><code class="java">@Entity
 @WriteBuffer(size = 150, strategy = WriteBuffer.STRATEGY.DEL_OLD)
    public static class BufferedBySizeDelOldObject extends UncachedObject {

    }
</code></pre>

<p>In this case, the buffer has a maximum of 150 entries, and if the buffer has reached that maximum, the oldest entries
    will just be deleted from buffer and hence NOT be written!</p>

<p>Possible strategies are:</p>

<ul>
    <li><code>WriteBuffer.STRATEGY.DEL_OLD</code>: delete oldest entries from buffer - use with caution</li>
    <li><code>WriteBuffer.STRATEGY.IGNORE_NEW</code>: Do not write the new entry - just discard it. use with caution
    </li>
    <li><code>WriteBuffer.STRATEGY.JUST_WARN</code>: just log a warning message, but store data anyway</li>
    <li><code>WriteBuffer.STRATEGY.WRITE_NEW</code>: write the new entry synchronously and wait for it to be finished
    </li>
    <li><code>WriteBuffer.STRATEGY.WRITE_OLD</code>: write some old data NOW, wait for it to be finished, than queue new
        entries
    </li>
</ul>

<p>That's it - rest is 100% transparent - just call <code>morphium.store(entity);</code> - the rest is done
    automatically.</p>

<p>internally it uses the <code>BufferedWriter</code> implementation, which can be changed, if needed (see configuration
    options below). Also, some config settings exist for switching off the buffered writing altogether - comes in handy
    when testing. have a closer look at the configuration options in <code>MorphiumConfig</code> which refer to <code>writeBuffer</code>
    or <code>BufferedWriter</code>.</p>

<p><strong>Read Cache</strong></p>

<p>Read caches are defined on type level with the annotation @Cache. There you can specify, how your cache should
    operate:</p>

<pre><code class="java">@Cache(clearOnWrite = true, maxEntries = 20000, strategy = Cache.ClearStrategy.LRU, syncCache = Cache.SyncCacheStrategy.CLEAR_TYPE_CACHE, timeout = 5000)
@Entity
public class MyCachedEntity {
.....
}
</code></pre>

<p>here a cache is defined, which has a maximum of 20000 entries. Those Entries have a lifetime of 5 seconds
    (timeout=5000). Which means, no element will stay longer than 5sec in cache. The strategy defines, what should
    happen, when you read additional object, and the cache is full:</p>

<ul>
    <li><code>Cache.ClearStartegy.LRU</code>: remove least recently used elements from cache</li>
    <li><code>Cache.ClearStrategy.FIFO</code>:first in first out - depending time added to cache</li>
    <li><p><code>Cache.ClearStrategy.RANDOM</code>: just remove some random entries</p>
        With <code>clearOnWrite=true</code> set, the local cache will be erased any time you write an entity of this
        typte to database. This prevents dirty reads. If set to false, you might end up with stale data (for as long as
        the timeout value) but produce less stress on mongo and be probably a bit faster.
    </li>
</ul>

<h4 id="cache-synchronization">cache synchronization</h4>

<p>as mentioned above, caching is of utter importance in production grade applications. Usually, caching in a clustered
    Environment is kind of a pain. As you need consider dirty reads and such. But <em>Morphium</em> caching works also
    fine in a clustered environment. Just start (instantiate) a <code>CacheSynchronizer</code> - and you're good to go!
</p>

<p>There are two implementations of the cache synchronizer:</p>

<ul>
    <li><code>WatchingCacheSynchronizer</code>: uses mongodbs <code>watch</code> - Feature to get informed about changes
        in collections via push.
    </li>
    <li><code>MessagingCacheSynchronizer</code>: uses messaging to inform cluster members about changes. This one has
        the advantage that you can send messages manually or when other events occur
    </li>
</ul>

<p>**Internals / Implementation details **</p>

<ul>
    <li><p><em>Morphium</em> uses the cache based on the search query, sort options and collection overrides given. This
        means that there might be duplicate cache entries. In order to minimize the memory usage, <em>Morphium</em> also
        uses an ID-Cache. So all results are just added to this id cache and those ids are added as result to the query
        cache.</p>
        the Caches are organized per type. This means, if your entity is not marked with @Cache, queries to this type
        won't be cached, even if you override the collection name.
    </li>
    <li>The cache is implemented completely unblocking and completely thread safe. There is almost no synchronized block
        in <em>Morphium</em>.
    </li>
</ul>

<p>It's a common problem, especially in clustered environments. How to synchronize caches on the different nodes. <em>Morphium</em>
    offers a simple solutions for it: On every write operation, a Message is stored in the Message queue (see
    MessagingSystem) and all nodes will clear the cache for the corresponding type (which will result in re-read of
    objects from mongo - keep that in mind if you plan to have a hundred hosts on your network) This is easy to use,
    does not cause a lot of overhead. Unfortunately it cannot be more efficient hence the Cache in <em>Morphium</em> is
    organized by searches.</p>

<p>the <em>Morphium</em> cache synchronizer does not issue messages for uncached entities or entities, where
    clearOnWrite is set to false. </p>

<p>Here is an example on how to use this:</p>

<pre><code class="java">    Messaging m=new Messaging(morphium,10000,true);
    MessagingCacheSynchronizer cs=new MessagingCacheSynchronizer(m,morphium);
</code></pre>

<p>Actually this is all there is to do, as the CacheSynchronizer registers itself to both <em>Morphium</em> and the
    messaging system.</p>

<p><strong>Change since 1.4.0</strong></p>

<p>Now the Caching is specified by every entity in the @Cache annotation using one Enum called SyncCacheStrategy.
    Possible Values are: NONE (Default), CLEAR_TYPE_CACHE (clear cache of all queries on change) and UPDATE_ENTRY
    (updates the entry itself), REMOVE_ENTRY_FROM_TYPE_CACHE (removes all entries from cache, containing this
    element)</p>

<pre><code class="java">enum SyncCacheStrategy {NONE, CLEAR_TYPE_CACHE, REMOVE_ENTRY_FROM_TYPE_CACHE, UPDATE_ENTRY}
</code></pre>

<p>UPDATE_ENTRY only works when updating records, not on drop or remove or update (like inc, set, push...). For example,
    if UPDATE_ENTRY is set, and you drop the collection, type cache will be cleared. </p>

<p><strong>Attention:</strong> UPDATE_ENTRY will result in dirty reads, as the Item itself is updated, but not the
    corresponding searches! </p>

<p>Meaning: assume you have a Query result cached, where you have all Users listed which have a certain role:</p>

<pre><code class="java">   Query&lt;User&gt; q=morphium.createQueryFor(User.class);
   q=q.f(&quot;role&quot;).eq(&quot;Admin&quot;);
   List&lt;User&gt; lst=q.asList();
</code></pre>

<p>Let's further assume you got 3 Users as a result. Now imagine, one node on your cluster changes the role of one of
    the users to something different than &quot;Admin&quot;. If you have a list of users that might be changed while you
    use them! Careful with that! More importantly: your cache holds a copy of that list of users for a certain amount of
    time. During that time you will get a dirty read. Meaning: you will get objects that actually might not be part of
    your query or you will not get that actually might (not so bad actually).</p>

<p>Better use REMOVE_ENTRY_FROM_TYPE_CACHE in that case, as it will keep everything in cache except your search results
    containing the updated element. Might also cause a dirty read (as the newly added elements might not be added to
    your results) but it keeps findings more or less correct.</p>

<p>As all these synchronizations are done by sending messages via the <em>Morphium</em> own messaging system (which
    means storing messages in DB), you should really consider just disabling cache in case of heavy updates as a read
    from Mongo might actually be lots faster then sync of caches.</p>

<p>Keep that in mind!</p>

<p><strong>Change since 1.3.07</strong></p>

<p>Since 1.3.07 you need to add a autoSync=true to your cache annotation, in order to have things synced. It tuned out,
    that automatic syncing is not always the best solution. So, you can still manually sync your caches.</p>

<p><strong>Manually Syncing the Caches</strong></p>

<p>The sync in <em>Morphium</em> can be controlled totally manually (since 1.3.07), just send your own Clear-Cache
    Message using the corresponding method in CacheSynchronizer.</p>

<pre><code class="java">   cs.sendClearMessage(CachedObject.class,&quot;Manual delete&quot;);
</code></pre>

<h4 id="auto-versioning">Auto-Versioning</h4>

<p>When it comes to dirty reads and such, you might want to use the auto-versioning feature of <em>Morphium</em>. This
    will give every entity a version number. If you want to write to MongoDB and the version number differs, you'd get
    an exception - meaning the database was modified before you tried to persist your data. This so called <em>optimistic
        locking</em> will help in most cases to avoid accidental overwriting of data.</p>

<p>To use auto-Versioning, just set the corresponding flag in the <code>@Entity</code>-annotation to <code>true</code>
    and define a <code>Long</code> in your class, that should hold the version number using the <code>@Version</code>-annotation.
</p>

<p><strong>Attention:</strong> do not change the version value manually, this will cause problems writing and will most
    probably cause loss of data!</p>

<h4 id="type-ids">Type IDs</h4>

<p>usually <em>Morphium</em> knows which collection holds which kind of data. When de-serializing it is easy to know,
    what class to instanciate. </p>

<p>But when it comes to polymorphism and containers (like lists and maps), things get compicated. <em>Morphium</em> adds
    in this case the class name as property to the document. Up until version 4.0.0 this was causing some problems when
    refactoring your Entities. If you changed the classname or the package name of that class, de-serializing was
    impossible (the classname was obviously wrong).</p>

<p>now you can just set the <code>typeId</code> in <code>@Entity</code> to be able refactor more easily. If you already
    have data, and you want to refactor your entitiy names, just add the <em>original</em> class name as type id!</p>

<h4 id="sequences">Sequences</h4>

<p>One of the very convenient features of SQL-Databases is the support for sequences. This is <em>very</em> useful when
    trying to have unique IDs.</p>

<p><em>Morphium</em> implements a feature very similar to SQL-Sequences. Hence it is also called
    <code>SequenceGenerator</code>.</p>

<p>A sequence is a simple implementation in <em>Morphium</em> that uses MongoDB to generate unique numbers. Example:</p>

<pre><code>SequenceGenerator sg = new SequenceGenerator(morphium, &quot;tstseq&quot;, 1, 1);
long v = sg.getNextValue();
assert (v == 1) : &quot;Value wrong: &quot; + v;
v = sg.getNextValue();
assert (v == 2);
</code></pre>

<p>As those generators use MongoDB for synchronization, they are cluster-safe and can be used by all clients of the same
    MongoDB simultaneously. No number will be delivered twice!</p>

<p>This test here uses several Threads to access the same <code>SequenceGenerator</code>:</p>

<pre><code class="java"> final SequenceGenerator sg1 = new SequenceGenerator(morphium, &quot;tstseq&quot;, 1, 0);
        Vector&lt;Thread&gt; thr = new Vector&lt;&gt;();
        final Vector&lt;Long&gt; data = new Vector&lt;&gt;();
        for (int i = 0; i &lt; 10; i++) {
            Thread t = new Thread(() -&gt; {
                for (int i1 = 0; i1 &lt; 25; i1++) {
                    long nv = sg1.getNextValue();
                    assert (!data.contains(nv)) : &quot;Value already stored? Value: &quot; + nv;
                    data.add(nv);
                    try {
                        Thread.sleep(10);
                    } catch (InterruptedException e) {
                    }
                }
            });
            t.start();
            thr.add(t);
        }
        log.info(&quot;Waiting for threads to finish&quot;);
        for (Thread t : thr) {
            t.join();
        }
        long last = -1;
        Collections.sort(data);
        for (Long l : data) {
            assert (last == l - 1);
            last = l;
        }
        log.info(&quot;done&quot;);
</code></pre>

<p>Here is an example, where the sequences are being used by <em>a lot</em> of separate threads each with its own
    connection to mongodb:</p>

<pre><code class="java">morphium.dropCollection(Sequence.class);
Thread.sleep(100); //wait for the drop to be persisted


//creating lots of sequences, with separate MongoDBConnections
//reading from the same sequence
//in different Threads
final Vector&lt;Long&gt; values=new Vector&lt;&gt;();
List&lt;Thread&gt; threads=new ArrayList&lt;&gt;();
final AtomicInteger errors=new AtomicInteger(0);
for (int i = 0; i &lt; 10; i++) {
    Morphium m=new Morphium(MorphiumConfig.fromProperties(morphium.getConfig().asProperties()));

    Thread t=new Thread(()-&gt;{
        SequenceGenerator sg1 = new SequenceGenerator(m, &quot;testsequence&quot;, 1, 0);
        for (int j=0;j&lt;100;j++){
            long l=sg1.getNextValue();
            log.info(&quot;Got nextValue: &quot;+l);
            if(values.contains(l)){
                log.error(&quot;Duplicate value &quot;+l);
                errors.incrementAndGet();
            } else {
                values.add(l);
            }
            try {
                Thread.sleep((long) (100*Math.random()));
            } catch (InterruptedException e) {
            }
        }
        m.close();
    });
    threads.add(t);
    t.start();
}

while (threads.size()&gt;0){
    //log.info(&quot;Threads active: &quot;+threads.size());
    threads.get(0).join();
    threads.remove(0);
    Thread.sleep(100);
}

assert(errors.get()==0);

</code></pre>

<p><strong>Attention</strong> after creating a new <code>SequenceGenerator</code> the <code>currentValue</code> will be
    <code>startValue-inc</code> in order so that <code>getNextValue()</code> will return <code>startValue</code> first.
</p>

<p>When migrating to <em>Morphium</em> 4.2.x or higher from older versions the sequences will not be compatible anymore
    due to a change in ID.</p>

<p>to fix that, you need to run the following command in mongoDB shell:</p>

<pre><code class="js">db.sequence.find({name:{$exists:true}}).forEach(function(x){db.sequence.deleteOne({_id:x._id}); x._id=x.name;delete x.name; db.sequence.save(x);});
</code></pre>

<h4 id="transparent-encryption-of-values">transparent encryption of values</h4>

<p><em>Morphium</em> implemented a client side version of auto encrypted fields. When defining a property, you can
    specify the value to be encrypted. <em>Morphium</em> provides an implementation of AESEncryption, but you could
    implement any other encryption. </p>

<p>In order for encryption to work, we need to provide a <code>ValueEncryptionProvider</code>. This is a very simple
    interface:</p>

<pre><code class="java">        package de.caluga.morphium.encryption;

        public interface ValueEncryptionProvider {
            void setEncryptionKey(byte[] key);
        
            void setEncryptionKeyBase64(String key);
        
            void setDecryptionKey(byte[] key);
        
            void sedDecryptionKeyBase64(String key);
        
            byte[] encrypt(byte[] input);
        
            byte[] decrypt(byte[] input);
        
        }
</code></pre>

<p>There are two implementations available: <code>AESEncryptionProvider</code> and <code>RSAEncryptionProvider</code>.
</p>

<p>Another interface being used is the <code>EncryptionKeyProvider</code>, a simple system for managing encryption keys:
</p>

<pre><code class="java">        package de.caluga.morphium.encryption;
        
        public interface EncryptionKeyProvider {
            void setEncryptionKey(String name, byte[] key);
        
            void setDecryptionKey(String name, byte[] key);
        
            byte[] getEncryptionKey(String name);
        
            byte[] getDecryptionKey(String name);
        
        }
</code></pre>

<p>The <code>DefaultEncrptionKeyProvider</code> acutally is a very simple key-value-store and needs to be filled
    manually. The implementation <code>PropertyEncryptionKeyProvider</code> reads those keys from <em>encrypted</em>
    property files.</p>

<p>Here is an example, on how to use the transparent encryption:</p>

<pre><code class="java">    @Entity
    public static class EncryptedEntity {
        @Id
        public MorphiumId id;

        @Encrypted(provider = AESEncryptionProvider.class, keyName = &quot;key&quot;)
        public String enc;

        @Encrypted(provider = AESEncryptionProvider.class, keyName = &quot;key&quot;)
        public Integer intValue;

        @Encrypted(provider = AESEncryptionProvider.class, keyName = &quot;key&quot;)
        public Float floatValue;

        @Encrypted(provider = AESEncryptionProvider.class, keyName = &quot;key&quot;)
        public List&lt;String&gt; listOfStrings;

        @Encrypted(provider = AESEncryptionProvider.class, keyName = &quot;key&quot;)
        public Subdoc sub;


        public String text;
    }



    @Test
    public void objectMapperTest() throws Exception {
        morphium.getEncryptionKeyProvider().setEncryptionKey(&quot;key&quot;, &quot;1234567890abcdef&quot;.getBytes());
        morphium.getEncryptionKeyProvider().setDecryptionKey(&quot;key&quot;, &quot;1234567890abcdef&quot;.getBytes());
        MorphiumObjectMapper om = morphium.getMapper();
        EncryptedEntity ent = new EncryptedEntity();
        ent.enc = &quot;Text to be encrypted&quot;;
        ent.text = &quot;plain text&quot;;
        ent.intValue = 42;
        ent.floatValue = 42.3f;
        ent.listOfStrings = new ArrayList&lt;&gt;();
        ent.listOfStrings.add(&quot;Test1&quot;);
        ent.listOfStrings.add(&quot;Test2&quot;);
        ent.listOfStrings.add(&quot;Test3&quot;);

        ent.sub = new Subdoc();
        ent.sub.intVal = 42;
        ent.sub.strVal = &quot;42&quot;;
        ent.sub.name = &quot;name of the document&quot;;

        //serializing the document needs to encrypt the data
        Map&lt;String, Object&gt; serialized = om.serialize(ent);
        assert (!ent.enc.equals(serialized.get(&quot;enc&quot;)));

        //checking deserialization used decryption
        EncryptedEntity deserialized = om.deserialize(EncryptedEntity.class, serialized);
        assert (deserialized.enc.equals(ent.enc));
        assert (ent.intValue.equals(deserialized.intValue));
        assert (ent.floatValue.equals(deserialized.floatValue));
        assert (ent.listOfStrings.equals(deserialized.listOfStrings));
    }
</code></pre>

<p>Please note, that the key <em>name</em> used for encryption and decryption is to be defined in the property
    configuration of the corresponding entity. </p>

<h4 id="binary-serialization">binary serialization</h4>

<p>the config of morphium does have a setting called <code>objectSerializationEnabled</code>. When set to
    <code>true</code> this will cause morphium to use the standard binary serialization of the JDK to store <em>any</em>
    instance of <em>any</em> class that implements <code>serializable</code><sup><a class="footnote" href="#fn4-7368"
                                                                                    id="fnr4-7368" title="see footnote">4</a></sup>.
</p>

<p>Another setting in the config called <code>warnOnNoEntitySerialization</code> will create a warning message in log,
    when this serialization takes place. </p>

<p>This is set to <code>true</code> by default, to make development easier. But you probably do not want to use it on
    heavy load entities.</p>

<p>To store the binary data, <em>Morphium</em> uses a helper class called <code>BinarySerializedObject</code>, which
    will be shown in MongoDB:</p>

<pre><code class="json">{
    &quot;_id&quot; : ObjectId(&quot;5f5bc1d8f8fd8247688e41f5&quot;),
    &quot;list&quot; : [ 
        {
            &quot;original_class_name&quot; : &quot;de.caluga.test.mongo.suite.base.NonEntitySerialization$NonEntity&quot;,
            &quot;_b64data&quot; : &quot;rO0ABXNyADtkZS5jYWx1Z2EudGVzdC5tb25nby5zdWl0ZS5Ob25FbnRpdHlTZXJpYWxpemF0aW9u\r\nJE5vbkVudGl0eV18gEK68jkAAgACTAAHaW50ZWdlcnQAE0xqYXZhL2xhbmcvSW50ZWdlcjtMAAV2\r\nYWx1ZXQAEkxqYXZhL2xhbmcvU3RyaW5nO3hwc3IAEWphdmEubGFuZy5JbnRlZ2VyEuKgpPeBhzgC\r\nAAFJAAV2YWx1ZXhyABBqYXZhLmxhbmcuTnVtYmVyhqyVHQuU4IsCAAB4cAAAACp0ABZUaGFuayB5\r\nb3UgZm9yIHRoZSBmaXNo&quot;
        }, 
        &quot;Some string&quot;
    ]
}
</code></pre>

<p>In this case, this &quot;Container&quot; does contain a list of non-entity objects:</p>

<pre><code class="java">
    @Entity
    public class NonEntityContainer {
        @Id
        private MorphiumId id;
        private List&lt;Object&gt; list;
        private HashMap&lt;String, Object&gt; map;

        public MorphiumId getId() {
            return id;
        }

        public void setId(MorphiumId id) {
            this.id = id;
        }

        public List&lt;Object&gt; getList() {
            return list;
        }

        public void setList(List&lt;Object&gt; list) {
            this.list = list;
        }

        public HashMap&lt;String, Object&gt; getMap() {
            return map;
        }

        public void setMap(HashMap&lt;String, Object&gt; map) {
            this.map = map;
        }
    }



    public class NonEntity implements Serializable {
        private String value;
        private Integer integer;

        public String getValue() {
            return value;
        }

        public void setValue(String value) {
            this.value = value;
        }

        public Integer getInteger() {
            return integer;
        }

        public void setInteger(Integer integer) {
            this.integer = integer;
        }

        @Override
        public String toString() {
            return &quot;NonEntity{&quot; +
                    &quot;value='&quot; + value + '\'' +
                    &quot;, integer=&quot; + integer +
                    '}';
        }
    }
</code></pre>

<p><strong>Attention:</strong> please keep in mind, that you cannot store non-entities directly. Only a member variable
    of an entity (even if it is in a list or Map) might be non-entities.</p>

<h4 id="complex-data-structures">complex data structures</h4>

<p>In the jUnit tests, <em>Morphium</em> is tested to support those complex data structures, like lists of lists, lists
    of maps or maps of lists of entities. I think, you'll get the picture:</p>

<pre><code class="java">  public static class CMapListObject extends MapListObject {
        private Map&lt;String, List&lt;EmbObj&gt;&gt; map1;
        private Map&lt;String, EmbObj&gt; map2;
        private Map&lt;String, List&lt;String&gt;&gt; map3;
        private Map&lt;String, List&lt;EmbObj&gt;&gt; map4;

        private Map&lt;String, Map&lt;String, String&gt;&gt; map5;
        private Map&lt;String, Map&lt;String, EmbObj&gt;&gt; map5a;
        private Map&lt;String, List&lt;Map&lt;String, EmbObj&gt;&gt;&gt; map6a;

        private List&lt;Map&lt;String, String&gt;&gt; map7;
        private List&lt;List&lt;Map&lt;String, String&gt;&gt;&gt; map7a;
        ....
</code></pre>

<p>have a look at the Tests in code on github for more examples. the main challenge here is, to determine the right type
    of elements in the list in order to be able to de-serialize them properly. In this case, de-serialization is done in
    background transparently:</p>

<pre><code class="java"> @Test
    public void testListOfListOfMap() {
        morphium.dropCollection(MapListObject.class);

        CMapListObject o = new CMapListObject();
        List&lt;List&lt;Map&lt;String, String&gt;&gt;&gt; lst = new ArrayList&lt;&gt;();
        List&lt;Map&lt;String, String&gt;&gt; l2 = new ArrayList&lt;&gt;();
        Map&lt;String, String&gt; map = new HashMap&lt;&gt;();
        map.put(&quot;k1&quot;, &quot;v1&quot;);
        map.put(&quot;k2&quot;, &quot;v2&quot;);
        l2.add(map);
        map = new HashMap&lt;&gt;();
        map.put(&quot;k11&quot;, &quot;v11&quot;);
        map.put(&quot;k21&quot;, &quot;v21&quot;);
        map.put(&quot;k31&quot;, &quot;v31&quot;);
        l2.add(map);
        lst.add(l2);

        l2 = new ArrayList&lt;&gt;();
        map = new HashMap&lt;&gt;();
        map.put(&quot;k15&quot;, &quot;v1&quot;);
        map.put(&quot;k25&quot;, &quot;v2&quot;);
        l2.add(map);
        map = new HashMap&lt;&gt;();
        map.put(&quot;k51&quot;, &quot;v11&quot;);
        map.put(&quot;k533&quot;, &quot;v21&quot;);
        map.put(&quot;k513&quot;, &quot;v31&quot;);
        l2.add(map);
        map = new HashMap&lt;&gt;();
        map.put(&quot;k512&quot;, &quot;v11&quot;);
        map.put(&quot;k514&quot;, &quot;v21&quot;);
        map.put(&quot;k513&quot;, &quot;v31&quot;);
        l2.add(map);

        lst.add(l2);
        o.setMap7a(lst);

        morphium.store(o);

        CMapListObject ml = morphium.findById(CMapListObject.class, o.getId());
        assert (ml.getMap7a().get(1).get(0).get(&quot;k15&quot;).equals(&quot;v1&quot;));
    }
</code></pre>

<p>as you see here, the deserialization is done transparently in background even on several levels &quot;down&quot;, the
    <code>CMapListObject</code> is initialized properly.</p>

<p><em>Caveat</em>: this can only work, if java knows the type of the elements in the list. As soon as there is a <code>List&lt;Object&gt;</code>
    in the type definition, morphium does not know, what the type might be. It will try to deserialize it (which will
    work if it is a proper entity), but might not work in all cases. If this detection fails, you'll likely end up
    getting a <code>ClassCastException</code>. If so, try to define the data structure more strictly or simplify it.</p>

<h4 id="support-for-mapreduce">Support for MapReduce</h4>

<p>To do complex aggregations and analysis of your data in MongoDB the first choice to do that was <em>MapReduce</em>.
    If necessary or convenient, you can use that with <em>Morphium</em> as well, although it is not as powerful as the
    <em>Aggregation Framework</em> (see below).</p>

<p>Here is a basic example on how to use <em>MapReduce</em>:</p>

<pre><code class="java">
    private void doSimpleMRTest(Morphium m) throws Exception {
        List&lt;UncachedObject&gt; result = m.mapReduce(UncachedObject.class, &quot;function(){emit(this.counter%2==0,this);}&quot;, &quot;function (key,values){var ret={_id:ObjectId(), value:\&quot;\&quot;, counter:0}; if (key==true) {ret.value=\&quot;even\&quot;;} else { ret.value=\&quot;odd\&quot;;} for (var i=0; i&lt;values.length;i++){ret.counter=ret.counter+values[i].counter;}return ret;}&quot;);
        assert (result.size() == 2);
        boolean odd = false;
        boolean even = false;
        for (UncachedObject r : result) {
            if (r.getValue().equals(&quot;odd&quot;)) {
                odd = true;
            }
            if (r.getValue().equals(&quot;even&quot;)) {
                even = true;
            }
            assert (r.getCounter() &gt; 0);
        }
        assert (odd);
        assert (even);
    }
</code></pre>

<p>the problem here is, that you need to write <em>JavaScript</em> code and hence need to switch between contexts,
    whereas the Aggregation support in <em>Morphium</em> lets you define the whole pipeline in Java.</p>

<h4 id="automatic-retries-on-error">automatic retries on error</h4>

<p>The write concern aka WriteSafety-Annotation in <em>Morphium</em> is not enough for being on the safe side. the
    WriteSafety only makes sure, that, if all is ok, data is written to the amount of nodes, you want it to be written.
    You define the safety level more or less in an Application point of view. This does not affect networking outage or
    other problems. Also in case of a failover during access, you will end up with an exception in application. In order
    to deal with the problem, the coding advice for MongoDB is, to have all accesses run in a loop so that you can retry
    on failure and hope for fast recovery. </p>

<p><em>Morphium</em> takes care of that: all access to mongo is done in a loop and <em>Morphium</em> tries to detect if
    that error is recoverable (like a failover) or not. there are several retry-settings in the config.</p>

<p><strong>retry settings in writers</strong></p>

<p><em>Morphium</em> has 3 different types of writers:</p>

<ul>
    <li>the normal writer: supports asynchronous and synchronous writes</li>
    <li>the async writer: forces asynchronous writes</li>
    <li>the buffered writer: stores write requests in a buffer and executes those on block</li>
</ul>

<p>This has some implications, as the core of <em>Morphium</em> is asynchronous, we need to make sure, there are not too
    many pending writes. (the &quot;pile&quot; is determined by the maximum amount of connections to mongo - hence this
    is something you won't need to configure)</p>

<p>This is where the retry settings for writers come in. When writing data, this data is either written synchronously or
    asynchronously. In the latter case, the requests tend to pile up on heavy load. And we need to handle the case, when
    this pile gets too high. This is the retry. When the pile of pending requests is too high, wait for a specified
    amount of time and try again to queue the operation. If that fails for all retries - throw an exception.</p>

<p><strong>Retry settings for Network errors</strong></p>

<p>As we had a really sh... network which causes problems more than once a day, we needed to come up with a solution for
    this as well. As our network does not fail for more than a couple of requests, the idea is to detect network
    problems and retry the operation after a certain amount of time. This setting is specified globally in
    <em>Morphium</em> config:</p>

<p>´´´java</p>

<pre><code>    morphiumConfig.setRetriesOnNetworkError(10);
    morphiumConfig.setSleepBetweenNetworkErrorRetries(500);
</code></pre>

<p>´´´</p>

<p>This causes <em>Morphium</em> to retry any operation on mongo 10 times (if a network related error occurs) and pause
    500ms between each try. This includes, reads, writes, updates, index creation and aggregation. If the access failed
    after the (in this case) 10th try - rethrow the networking error to the caller.</p>

<h2 id="configuring-morphium-morphiumconfig">configuring <em>Morphium</em>: <code>MorphiumConfig</code></h2>

<p>MorphiumConfig is the class to encapsulate all settings for <em>Morphium</em>. The most obvious settings are the host
    seed and port definitions. But there is a ton of additional settings available.</p>

<h3 id="different-sources">Different sources</h3>

<h4 id="json">Json</h4>

<p>The standard <code>toString()</code>method of MorphiumConfig creates an Json String representation of the
    configuration. to set all configuration options from a json string, just call <code>createFromJson</code>.</p>

<h4 id="properties">Properties</h4>

<p>the configuration can be stored and read from a property object.</p>

<p><code>MorphiumConfig.fromProperties(Properties p);</code> Call this method to set all values according to the given
    properties. You also can pass the properties to the constructor to have it configured.</p>

<p>To get the properties for the current configuration, call <code>asProperties()</code> on a configured MorphiumConfig
    Object.</p>

<p>Here is an example property-file:</p>

<pre><code>    maxWaitTime=1000
    maximumRetriesBufferedWriter=1
    maxConnections=100
    retryWaitTimeAsyncWriter=100
    maxAutoReconnectTime=5000
    blockingThreadsMultiplier=100
    housekeepingTimeout=5000
    hosts=localhost\:27017, localhost\:27018, localhost\:27019
    retryWaitTimeWriter=1000
    globalCacheValidTime=50000
    loggingConfigFile=file\:/Users/stephan/_Morphium_/target/classes/_Morphium_-log4j-test.xml
    writeCacheTimeout=100
    connectionTimeout=1000
    database=_Morphium__test
    maximumRetriesAsyncWriter=1
    maximumRetriesWriter=1
    retryWaitTimeBufferedWriter=1000
</code></pre>

<p>The minimal property file would define only <code>hosts</code> and <code>database</code>. All other values would be
    defaulted.</p>

<p>If you want to specify classes in the config (like the Query Implementation), you need to specify the full qualified
    class name, e.g. <code>de.caluga.morphium.customquery.QueryImpl</code></p>

<h4 id="java-code">Java-Code</h4>

<p>The most straight forward way of configuring <em>Morphium</em> is, using the object directly. This means you call the
    getters and setters according to the given variable names above (like <code>setMaxAutoReconnectTime()</code>).</p>

<p>The minimum configuration is explained above: you only need to specify the database name and the host(s) to connect
    to. All other settings have sensible defaults, which should work for most cases.</p>

<h3 id="configuration-options">Configuration Options</h3>

<p>There are a lot of settings and customizations you can do within <em>Morphium</em>. Here we discuss <em>all</em> of
    them:</p>

<ul>
    <li><em>loggingConfigFile</em>: can be set, if you want <em><em>Morphium</em></em> to configure your log4j for you.
        <em>Morphium</em> itself has a dependency to log4j (see Dependencies).
    </li>
    <li><em>camelCaseConversion</em>: if set to false, the names of your entities (classes) and fields won't be
        converted from camelcase to underscore separated strings. Default is <code>true</code> (convert to camelcase)
    </li>
    <li><em>maxConnections</em>: Maximum Number of connections to be built to mongo, default is 10</li>
    <li><em>houseKeepingTimeout</em>: the timeout in ms between cache housekeeping runs. Defaults to 5sec</li>
    <li><em>globalCacheValidTime</em>: how long are Cache entries valid by default in ms. Defaults to 5sek</li>
    <li><em>writeCacheTimeout</em>: how long to pause between buffered writes in ms. Defaults to 5sek</li>
    <li><em>database</em>: Name of the Database to connect to.</li>
    <li><em>connectionTimeout</em>: Set a value here (in ms) to specify how long to wait for a connection to mongo to be
        established. Defaults to 0 (⇒ infinite)
    </li>
    <li><em>socketTimeout</em>: how long to wait for sockets to be established, defaults to 0 as well</li>
    <li><em>checkForNew</em>: This is something interesting related to the creation of ids. Usually Ids in mongo are of
        type <code>ObjectId</code>. Anytime you write an object with an <code>_id</code> of that type, the document is
        either updated or inserted, depending on whether or not the ID is available or not. If it is inserted, the newly
        created ObjectId is being returned and add to the corresponding object. But if the id is not of type ObjectId,
        this mechanism will fail, no objectId is being created. This is no problem when it comes to new creation of
        objects, but with updates you might not be sure, that the object actually is new or not. If this obtion is set
        to <code>true</code> <em><em>Morphium</em></em> will check upon storing, whether or not the object to be stored
        is already available in database and would update.
    </li>
    <li><em>writeTimeout</em>: this timeout determines how long to wait until a write to mongo has to be finshed.
        Default is <code>0</code>⇒ no timeout
    </li>
    <li><em>maximumRetriesBufferedWriter</em>: When writing buffered, how often should retry to write the data until an
        exception is thrown. Default is 10
    </li>
    <li><em>retryWaitTimeBufferedWriter</em>: Time to wait between retries</li>
    <li><em>maximumRetriesWriter</em>, <em>maximumRetriesAsyncWriter</em>: same as <em>maximumRetriesBufferedWriter</em>,
        but for direct storage or asynchronous store operation.
    </li>
    <li><em>retryWaitTimeWriter</em>, <em>retryWaitTimeAsyncWriter</em>: similar to <em>retryWaitTimeBufferedWriter</em>,
        but for the according writing type
    </li>
    <li><em>globalW</em>: W sets the number of nodes to have finished the write operation (according to your safe and j
        / fsync settings)
    </li>
    <li><em>maxWaitTime</em>: Sets the maximum time that a thread will block waiting for a connection.</li>
    <li><em>serverSelectionTimeout</em>: Defines how long the driver will wait for server selection to succeed before
        throwing an exception
    </li>
    <li><em>writeBufferTime:</em> Timeout for buffered writes. Default is 0</li>
    <li><em>autoReconnect</em>: if set to <code>true</code> connections are re-established, when lost. Default is <code>true</code>
    </li>
    <li><em>maxAutoReconnectTime</em>: how long to try to reconnect (in ms). Default is <code>0</code>⇒ try as long as
        it takes
    </li>
    <li><em>mongoLogin</em>,<em>mongoPassword</em>: User Credentials to connect to MongoDB. Can be null.</li>
    <li><em>mongoAdminUser</em>, <em>mongoAdminPwd</em>: Credentials to do admin tasks, like get the replicaset status.
        If not set, use mongoLogin instead.
    </li>
    <li><em>autoValuesEnabled</em>: <em>Morphium</em> supports automatic values being set to your POJO. These are
        configured by annotations (<code>@LasChange</code>, <code>@CreationTime</code>, <code>@LastAccess</code>, ...).
        If you want to switch this off <em>globally</em>, you can set it in the config. Very useful for test
        environments, which should not temper with productional data. By default the auto values are <em>enabled</em>.
    </li>
    <li><em>readCacheEnabled</em>: Globally enable or disable readcache. This only affects entities with a
        <code>@Cache</code> annotation. By default it's enabled.
    </li>
    <li><em>asyncWritesEnabled</em>: Globally enable or disalbe async writes. This only affects entities with a <code>@AsyncWrites</code>annotation
    </li>
    <li><em>bufferedWritesEnabled</em>: Globally enable or disable buffered writes. This only affects entities with a
        <code>@WriteBuffer</code> annotation
    </li>
    <li><code>defaultReadPreference</code>: whether to read from primary, secondary or nearest by default. Can be
        defined with the <code>@ReadPreference</code> annotation for each entity.
    </li>
    <li><code>replicaSetMonitoringTimeout</code>: time interval to update replicaset status.</li>
    <li><em>retriesOnNetworkError</em>: if you happen to have an unreliable network, maybe you want to retry writes /
        reads upon network error. This settings sets the number of retries for that case.
    </li>
    <li><em>sleepBetweenNetworkErrorRetries</em>: set the time to wait between network error retries.</li>
    <li><em>autoIndexAndCappedCreationOnWrite</em>: This setting is by default <em>true</em> which means, that <em>Morphium</em>
        keeps a list of existing collections. When a collection would be created automatically by writing to it, <em>Morphium</em>
        can then and only then have all indexes and capped settings configured for that specific collection. Causes a
        little overhead on write access to see, if a collection exists. Probably a good idea to switch off in production
        environment, but for development it makes things easier.
    </li>
</ul>

<p>In addition to those settings describing the behaviour of <em><em>Morphium</em></em>, you can also define custom
    classes to be used internally:</p>

<ul>
    <li><em>omClass</em>: here you specify the class, that should be used for mapping POJOs (your entities) to <code>Documnet</code>.
        By Default it uses the <code>ObjectMapperImpl</code>. Your custom implementation must implement the interface
        <code>ObjectMapper</code>.
    </li>
    <li><em>iteratorClass</em>: set the Iterator implementation to use. By default <code>MorphiumIteratorImpl</code>is
        being used. Your custom implementation must implement the interface <code>MorphiumIterator</code></li>
    <li><em>aggregatorClass</em>: this is <em><em>Morphium</em></em>'s representation of the aggregator framework. This
        can be replaced by a custom implementation if needed. Implements <code>Aggregator</code> interface
    </li>
    <li><em>aggregatorFactoryClass</em>: this is <em><em>Morphium</em></em>'s representation of the aggregator
        framework. This can be replaced by a custom implementation if needed. Implements <code>AggregatorFactory</code>
        interface
    </li>
    <li><em>queryClass</em> and <em>fieldImplClass</em>: this is used for Queries. If you want to take control over how
        queries ar built in <em><em>Morphium</em></em> and on how fields within queries are represented, you can replace
        those two with your custom implementation.
    </li>
    <li><em>queryFactoryClass</em>: query factory implementation, usually just creates a Query-Object. Custom
        implementations need to implement the <code>QueryFactory</code> interface.
    </li>
    <li><em>cache</em>: Set your own implementation of the cache. It needs to implement the <code>MorphiumCache</code>
        interface. Default is <code>MorphiumCacheImpl</code>. You need to specify a fully configured cache object here,
        not only a class object.
    </li>
    <li><em>driverClass</em>: Set the driver implementation, you want to use. This is a string, set the class name here.
        E.g. <code>MorphiumConfig.setDriverClass(MetaDriver.class.getName()</code>. Custom implementations need to
        implement the <code>MorphiumDriver</code> interface. By default the <code>MongodbDriver</code> is used, which
        connects to mongo using the official Java driver. But there are some other implementations, that do have some
        advantages (like the inMemoryDriver or the ones from the project <a
                href="https://github.com/sboesebeck/morphium-drivers">here</a>.
    </li>
</ul>

<p>In Mongo until V 2.4 authentication and user privileges were not really existent. With 2.4, roles are introduces
    which might make it a bit more complicated to get things working.</p>

<h3 id="authentication">authentication</h3>

<p><em>Morphium</em> supports authentication, of course, but on startup. So usually you have an application user, which
    connects to database. Login to mongo is configured as follows:</p>

<pre><code class="java">    MorphiumConfig cfg=new Morpiumconfig(...);
    ...
    cfg.setMongoLogin(&quot;tst&quot;);
    cfg.setMongoPassword(&quot;tst&quot;);
</code></pre>

<p>This user usually needs to have read/write access to the database. If you want your indices to be created
    automatically by you, this user also needs to have the role <em>dbAdmin</em> for the corresponding database. If you
    use <em>Morphium</em> with a replicaset of mongo nodes, <em>Morphium</em> needs to be able to get access to local
    database and get the replicaset status. In order to do so, either the mongo user needs to get additional roles
    (clusterAdmin and read to local db), or you specify a special user for that task, which has excactly those roles.
    <em>Morphium</em> authenticates with that different user for accessing replicaSet status (and only for getting the
    replicaset status) and is configured very similar to the normal login:</p>

<pre><code class="java">     cfg.setMongoAdminUser(&quot;adm&quot;);
     cfg.setMongoAdminPwd(&quot;adm&quot;);
</code></pre>

<h4 id="corresponding-mongod-config">corresponding MongoD Config</h4>

<p>You need to run your mongo nodes with -auth (or authenticate = true set in config) and if you run a replicaset, those
    nodes need to share a key file or kerberos authentication. (see
    http://docs.mongodb.org/manual/reference/user-privileges/) Let's assume, that all works for now. Now you need to
    specify the users. One way of doing that is the following:</p>

<ul>
    <li><p>add the user for mongo to your main database (in our case tst)</p></li>
    <li><p>add an admin user for your own usage from shell to admin db (with all privileges)</p></li>
    <li><p>add the clusterAdmin user to admin db as well, grant read access to local</p>

        <pre><code class="js">use admin
db.addUser({user:&quot;adm&quot;,pwd:&quot;adm&quot;,
                   roles:[&quot;read&quot;,&quot;clusterAdmin&quot;], 
                   otherDBRoles:{local:[&quot;read&quot;]}
                  })
db.addUser({user:&quot;admin&quot;,pwd:&quot;admin&quot;,
                  roles:[&quot;dbAdminAnyDatabase&quot;,
                            &quot;readWriteAnyDatabase&quot;,
                            &quot;clusterAdmin&quot;,
                            &quot;userAdminAnyDatabase&quot;]
                   })

use morphium_test
db.addUser({user:&quot;tst&quot;,pwd:&quot;tst&quot;,roles:[&quot;readWrite&quot;,&quot;dbAdmin&quot;]})
</code></pre>

        <p>Here morphium_test is your application database <em>Morphium</em> is connected to primarily. The admin db is
            a system database.</p></li>
</ul>

<p>This is far away from being a complete guide, I hope this just gets you started with authentication....</p>

<h2 id="entity-definition">Entity Definition</h2>

<p>Entities in <em><em>Morphium</em></em> are just &quot;Plain old Java Objects&quot; (POJOs). So you just create your
    data objects, as usual. You only need to add the annotation <code>@Entity</code> to the class, to tell <em><em>Morphium</em></em>
    &quot;Yes, this can be stored&quot;. The only additional thing you need to take care of is the definition of an
    ID-Field. This can be any field in the POJO identifying the instance. Its best, to use <code>ObjectID</code> as type
    of this field, as these can be created automatically and you don't need to care about those as well.</p>

<p>If you specify your ID to be of a different kind (like String), you need to make sure, that the String is set, when
    the object will be written. Otherwise you might not find the object again. So the shortest Entity would look like
    this:</p>

<pre><code class="java">       @Entity
        public class MyEntity {
           @Id private ObjectId id;
           //.. add getter and setter here
        }
</code></pre>

<h3 id="indexes">indexes</h3>

<p>Indexes are <em>critical</em> in mongo, so you should definitely define your indexes as soon as possible during your
    development. Indexes can be defined on the Entity itself, there are several ways to do so: - @Id always creates an
    index - you can add an <code>@Index</code> to any field to have that indexed:</p>

<p>@Index</p>

<p>private String name;</p>

<p>you can define combined indexes using the <code>@Index</code> annotation at the class itself:</p>

<pre><code class="java">        @Index({&quot;counter, name&quot;,&quot;value,thing,-counter&quot;}
        public class MyEntity {
</code></pre>

<p>This would create two combined indexes: one with <code>counter</code> and <code>name</code> (both ascending) and one
    with <code>value</code>, <code>thing</code> and descending <code>counter</code>. You could also define single field
    indexes using this annotations, but it's easier to read adding the annotation directly to the field.</p>

<p>Indexes will be created automatically if you <em>create</em> the collection. If you want the indexes to be created,
    even if there is already data stores, you need to call <code>morphium.ensureIndicesFor(MyEntity.class)</code>- You
    also may create your own indexes, which are not defined in annotations by calling
    <code>morphium.ensureIndex()</code>. As parameter you pass on a Map containing field name and order (-1 or 1) or
    just a prefixed list of strings (like<code>&quot;-counter&quot;,&quot;name&quot;</code>).</p>

<p>Every Index might have a set of options which define the kind of this index. Like <code>buildInBackground</code> or
    <code>unique</code>. You need to add those as second parameter to the Index-Annotation:</p>

<pre><code class="java">@Entity
@Index(value = {&quot;-name, timer&quot;, &quot;-name, -timer&quot;, &quot;lst:2d&quot;, &quot;name:text&quot;}, 
            options = {&quot;unique:1&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;})
public static class IndexedObject {
</code></pre>

<p>here 4 indexes are created. The first two are more or less standard, wheres the <code>lst</code> index is a
    geospatial one and the index on <code>name</code> is a text index (only since mongo 2.6). If you need to define
    options for one of your indexes, you need to define it for all of them (here, only the first index is unique).</p>

<h4 id="text-indexes">Text indexes</h4>

<p>MongoDB has a built in text search functionality since V3.x. This can be used in command line, or using
    <em>Morphium</em>. In order for it to work, a <em>text index</em> needs to be defined for the entity/collection.
    Here an example for an entity called <code>Person</code>:</p>

<pre><code class="java">@Entity
    @Index(value = {&quot;vorname:text,nachname:text,anrede:text,description:text&quot;, &quot;age:1&quot;}, options = {&quot;name:myIdx&quot;})
    public static class Person { 
        //properties and getters/setters left out for readability
    }
</code></pre>

<p>in this case, a text index was built on fields <code>vorname</code>, <code>nachname</code>, <code>andrede</code> and
    <code>description</code>.</p>

<p>To use the index, we need to create a text query<sup><a class="footnote" href="#fn5-7368" id="fnr5-7368"
                                                           title="see footnote">5</a></sup>:</p>

<pre><code class="java">@Test
public void textIndexTest() throws Exception {
    morphium.dropCollection(Person.class);
    try {
        morphium.ensureIndicesFor(Person.class);
    } catch (Exception e) {
        log.info(&quot;Text search not enabled - test skipped&quot;);
        return;
    }
    createData();
    TestUtils.waitForWrites(morphium,log);
    Query&lt;Person&gt; p = morphium.createQueryFor(Person.class);
    List&lt;Person&gt; lst = p.text(Query.TextSearchLanguages.english, &quot;hugo&quot;, &quot;bruce&quot;).asList();
    assert (lst.size() == 2) : &quot;size is &quot; + lst.size();
    p = morphium.createQueryFor(Person.class);
    lst = p.text(Query.TextSearchLanguages.english, false, false, &quot;Hugo&quot;, &quot;Bruce&quot;).asList();
    assert (lst.size() == 2) : &quot;size is &quot; + lst.size();
}
</code></pre>

<p>In this case, there is some Data created, which puts the name of some superheroes in a mongo. Searching for the text
    ist something different than searching via regular expressions, because Text Indexes are way more efficient in that
    case.</p>

<p>If you need more information on text indexes, have a look at MongoDBs documentation and take a look at the Tests for
    TextIndexes within the source code of <em>Morphium</em>.</p>

<h3 id="capped-collections">capped collections</h3>

<p>Similar as with indexes, you can define you collection to be capped using the <code>@Capped</code> annotation. This
    annotation takes two arguments: the maximum number of entries and the maximum size. If the collection does not
    exist, it will be created as capped collection using those two values. You can always ensureCapped your collection,
    unfortunately then only the <code>size</code> parameter will be honoured.</p>

<h2 id="querying">Querying</h2>

<p>Querying is done via the Query-Object, which is created by <em><em>Morphium</em></em> itself (using the Query
    Factory). The definition of the query is done using the fluent interface:</p>

<pre><code class="java">Query&lt;MyEntity&gt; query=_Morphium_.createQueryFor(MyEntity.class);
query=query.f(&quot;id&quot;).eq(new ObjectId());
query=query.f(&quot;valueField&quot;).eq(&quot;the value&quot;);
query=query.f(&quot;counter&quot;).lt(22);
query=query.f(&quot;personName&quot;).matches(&quot;[a-zA-Z]+&quot;);
query=query.limit(100).sort(&quot;counter&quot;);
</code></pre>

<p>In this example, I refer to several fields of different types. The Query itself is always of the same basic
    syntax:</p>

<pre><code class="java">queryObject=queryObject.f(FIELDNAME).OPERATION(Value);
queryObject=queryObject.skip(NUMBER); //skip a number of entreis
queryObject=queryObject.limig(NUMBER); // limit result
queryObject.sort(FIELD_TO_SORTBY);`    
</code></pre>

<p>As field name you may either use the name of the field as it is in mongo or the name of the field in java. If you
    specify an unknown field to <em><em>Morphium</em></em>, a <code>RuntimeException</code> will be raised.</p>

<p>For definition of the query, it's also a good practice to define enums for all of your fields. This makes it hard to
    have mistypes in a query:</p>

<pre><code class="java">        public class MyEntity {
              //.... field definitions
              public enum Fields { id, value, personName,counter, }
        }
</code></pre>

<p>There is a IntelliJ plugin (&quot;GeneratePropertyEnums&quot;) that is used for creating those enums automatically.
    Then, when defining the query, you don't have to type in the name of the field, just use the field enum:</p>

<p><code>query=query.f(MyEntity.Fields.counter).eq(123);</code></p>

<p>This avoids typos and shows compile time errors, when a field was renamed for whatever reason. </p>

<p>After you defined your query, you probably want to access the data in mongo. Via <em><em>Morphium</em></em>,there are
    several possibilities to do that: - <code>queryObject.get()</code>: returns the first object matching the query,
    only one. Or null if nothing matched - <code>queryObject.asList()</code>: return a list of all matching objects.
    Reads all data in RAM. Useful for small amounts of data - <code>Iterator&lt;MyEntity&gt;
        it=queryObject.asIterator()</code>: creates a <code>MorphiumIterator</code> to iterate through the data, which
    does not read all data at once, but only a couple of elements in a row (default 10).</p>

<h3 id="simple-queries">Simple queries</h3>

<p>most of your queries probably are simple ones. like searching for a special id or value. This is done rather simply
    with the query-Object: morphium.createQueryFor(MyEntity.class).f(&quot;field&quot;).eq(value) if you add more
    f(fields) to the query, they will be concatenated by a logical AND. so you can do something like:</p>

<pre><code class="java">    Query&lt;UncachedObject&gt; q=morphium.createQueryFor(UncachedObject.class);
    q.f(&quot;counter&quot;).gt(10).f(&quot;counter&quot;).lt(20);
</code></pre>

<p>This would result in a query like: &quot;All Uncached Objects, where counter is greater than 10 and counter is less
    then 20&quot;.</p>

<h3 id="or-queries">Or Queries</h3>

<p>in addition to those AND-queries you can add an unlimited list of queries to it, which will be concatenated by a
    logical OR.</p>

<pre><code class="java">   q.f(&quot;counter&quot;).lt(100).or(q.q().f(&quot;value&quot;).eq(&quot;Value 12&quot;), q.q().f(&quot;value&quot;).eq(&quot;other&quot;));
</code></pre>

<p>This would create a query like: &quot;all UncachedObjects where counter is less than 100 and (value is 'value 12' or
    value is 'other')&quot;</p>

<p>the Method q() creates a new empty query for the same object. It's a convenience Method. Please be careful, never use
    your query Object in the parameter list of or - this would cause and endless loop! ATTENTION here!</p>

<p>This gives you the possibility to create rather complex queries, which should handle about 75% of all cases. Although
    you can also add some NOR-Queries as well. These are like &quot;not or&quot;-Queries....</p>

<pre><code class="java">   q.f(&quot;counter&quot;).lt(100).nor(q.q().f(&quot;counter&quot;).eq(90), q.q().f(&quot;counter&quot;).eq(55));
</code></pre>

<p>this would result in a query like: &quot;All query objects where counter is less than 100 and not (counter=90 or
    counter=55).</p>

<p>this adds another complexity level to the queries ;-)</p>

<p>If that's not enough, specify your own query in &quot;mongo&quot;-Syntax.</p>

<p>You can also specify your own query object (Map&lt;String,Object&gt;) in case of a very complex query. This is part
    of the Query-Object and can be used rather easily:</p>

<pre><code class="java">        Map&lt;String,Object&gt; query=new HashMap&lt;&gt;();
        query.put(&quot;counter&quot;,UtilsMap.of(&quot;$lt&quot;,10));
        Query&lt;UncachedObject&gt; q=MorphiumSingleton.get().createQueryFor(UncachedObject.class);
        List&lt;UncachedObject&gt; lst=q.complexQuery(query);
</code></pre>

<p>Although, in this case the query is a very simple one (counter &lt; 10), but I think you get the Idea....</p>

<h4 id="limitations">Limitations</h4>

<p>Well, the fluent query interface does have its limitations. So its not possible to have a certain number of
    or-concatenated queries (like (counter==14 or Counter &lt;10) and (counter &gt;50 or counter ==30)). I'm not sure,
    this is very legible... </p>

<h3 id="the-iterator">the Iterator</h3>

<p><em><em>Morphium</em></em> has support for a special Iterator, which steps through the data, a couple of elements at
    a time. By Default this is the standard behaviour. But the _<em>Morphium</em>_Iterator ist quite capable:</p>

<ul>
    <li><code>queryObject.asIterable()</code> will stepp through the result list, 10 at a time</li>
    <li><code>queryObject.asIterable(100)</code> will step through the result list, 100 at a time</li>
    <li><code>queryObject.asIterable(100,5)</code> will step through the result list, 100 at a time and keep 4 chunks of
        100 elements each as prefetch buffers. Those will be filled in background.
    </li>
    <li><code>MorphiumIterator it=queryObject.asIterable(100,5); it.setmultithreadedAccess(true);</code> use the same
        iterator as before, but make it thread safe.
    </li>
</ul>

<p><strong>Description</strong></p>

<p>Problem is, when dealing with huge tables or lots of data, you'd probably include paging to your queries. You would
    read data in chunks of for example 100 objects to avoid memory overflows. This is now available by <em>Morphium</em>.
    The new MorphiumIterator works as Iterable or Iterator - whatever you like. It's included in the Query-interface and
    can be used very easily:</p>

<pre><code class="java">Query&lt;Type&gt; q=morphium.createQueryFor(Type.class);
q=q.f(&quot;field&quot;).eq..... //whatever

for (Type t:q.asIterable()) {
   //do something with t
}
</code></pre>

<p>This creates an iterator, reading all objects from the query in chunks of 10... if you want to read them one by one,
    you only ned to give the chunk-size to the call:</p>

<pre><code class="java">for (Type t:q.asIterable(1)) {
   //now reads every single Object from db
}
</code></pre>

<p>You can also use the iterator as in the &quot;good ol' days&quot;.</p>

<pre><code class="java">   Iterator&lt;Type&gt; it=q.asIterable(100);  //reads objects in chunks of 100
   while (it.hasNext()) {
    ... //do something
   }
</code></pre>

<p>If you use the MorphiumIterator as the type it actually is, you'd get even more information:</p>

<pre><code class="java">   MorphiumIterator&lt;Type&gt; it=q.asIterable(100);
   it.next();
   ....
   long count=it.getCount(); //returns the number of objects to be read
   int cursorPos=it.getCursor(); //where are we right now, how many did we read
   it.ahead(5); //jump ahead 5 objects
   it.back(4); //jump back 
   int bufferSize=it.getCurrentBufferSize(); //how many objects are currently stored in RAM
   List&lt;Type&gt; lst=it.getCurrentBuffer(); //get the objects in RAM
</code></pre>

<p><strong>Attention</strong>: the count is the number of objects matching the query at the instanciation of the
    iterator. This ensures, that the iterator terminates. The Query will be executed every time the buffer boundaries
    are reached. It might cause unexpected results, if the sort of the query is wrong.</p>

<p>For example:</p>

<pre><code class="java">   //created Uncached Objects with counter 1-100; value is always &quot;v&quot;
   Query&lt;UncachedObject&gt; qu=morphium.createQueryFor(UncachedObject.class).sort(&quot;-counter&quot;);
   for (UncachedObject u:qu.asIterable()) {
       UncachedObject uc=new UncachedObject();
            uc.setCounter(u.getCounter()+1);
            uc.setValue(&quot;WRONG!&quot;);
            MorphiumSingleton.get().store(uc);
            log.info(&quot;Current Counter: &quot;+u.getCounter()+&quot; and Value: &quot;+u.getValue());
   }
</code></pre>

<p>The output is as follows:</p>

<pre><code>14:21:10,494 INFO  [main] IteratorTest: Current Counter: 100 and Value: v
14:21:10,529 INFO  [main] IteratorTest: Current Counter: 99 and Value: v
14:21:10,565 INFO  [main] IteratorTest: Current Counter: 98 and Value: v
14:21:10,610 INFO  [main] IteratorTest: Current Counter: 97 and Value: v
14:21:10,645 INFO  [main] IteratorTest: Current Counter: 96 and Value: v
14:21:10,680 INFO  [main] IteratorTest: Current Counter: 95 and Value: v
14:21:10,715 INFO  [main] IteratorTest: Current Counter: 94 and Value: v
14:21:10,751 INFO  [main] IteratorTest: Current Counter: 93 and Value: v
14:21:10,786 INFO  [main] IteratorTest: Current Counter: 92 and Value: v
14:21:10,822 INFO  [main] IteratorTest: Current Counter: 91 and Value: v
14:21:10,857 INFO  [main] IteratorTest: Current Counter: 96 and Value: WRONG!
14:21:10,892 INFO  [main] IteratorTest: Current Counter: 95 and Value: v
14:21:10,927 INFO  [main] IteratorTest: Current Counter: 95 and Value: WRONG!
14:21:10,963 INFO  [main] IteratorTest: Current Counter: 94 and Value: v
14:21:10,999 INFO  [main] IteratorTest: Current Counter: 94 and Value: WRONG!
14:21:11,035 INFO  [main] IteratorTest: Current Counter: 93 and Value: v
14:21:11,070 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,105 INFO  [main] IteratorTest: Current Counter: 92 and Value: v
14:21:11,140 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:11,175 INFO  [main] IteratorTest: Current Counter: 91 and Value: v
14:21:11,210 INFO  [main] IteratorTest: Current Counter: 94 and Value: WRONG!
14:21:11,245 INFO  [main] IteratorTest: Current Counter: 94 and Value: WRONG!
14:21:11,284 INFO  [main] IteratorTest: Current Counter: 93 and Value: v
14:21:11,328 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,361 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,397 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,432 INFO  [main] IteratorTest: Current Counter: 92 and Value: v
14:21:11,467 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:11,502 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:11,538 INFO  [main] IteratorTest: Current Counter: 91 and Value: v
14:21:11,572 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,607 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,642 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,677 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,713 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,748 INFO  [main] IteratorTest: Current Counter: 92 and Value: v
14:21:11,783 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:11,819 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:11,853 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:11,889 INFO  [main] IteratorTest: Current Counter: 91 and Value: v
14:21:11,923 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,958 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:11,993 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:12,028 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:12,063 INFO  [main] IteratorTest: Current Counter: 92 and Value: v
14:21:12,098 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,133 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,168 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,203 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,239 INFO  [main] IteratorTest: Current Counter: 91 and Value: v
14:21:12,273 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:12,308 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:12,344 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:12,379 INFO  [main] IteratorTest: Current Counter: 92 and Value: v
14:21:12,413 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,448 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,487 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,521 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,557 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,592 INFO  [main] IteratorTest: Current Counter: 91 and Value: v
14:21:12,626 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:12,662 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:12,697 INFO  [main] IteratorTest: Current Counter: 92 and Value: v
14:21:12,733 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,769 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,804 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,839 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,874 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,910 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:12,945 INFO  [main] IteratorTest: Current Counter: 91 and Value: v
14:21:12,980 INFO  [main] IteratorTest: Current Counter: 93 and Value: WRONG!
14:21:13,015 INFO  [main] IteratorTest: Current Counter: 92 and Value: v
14:21:13,051 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,085 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,121 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,156 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,192 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,226 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,262 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,297 INFO  [main] IteratorTest: Current Counter: 91 and Value: v
14:21:13,331 INFO  [main] IteratorTest: Current Counter: 92 and Value: v
14:21:13,367 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,403 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,446 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,485 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,520 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,556 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,592 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,627 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,662 INFO  [main] IteratorTest: Current Counter: 91 and Value: v
14:21:13,697 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,733 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,768 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,805 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,841 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,875 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,911 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,946 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:13,982 INFO  [main] IteratorTest: Current Counter: 92 and Value: WRONG!
14:21:14,017 INFO  [main] IteratorTest: Current Counter: 91 and Value: v
14:21:14,017 INFO  [main] IteratorTest: Cleaning up...
14:21:14,088 INFO  [main] IteratorTest: done...
</code></pre>

<p>The first chunk is ok, but all that follow are not. Fortunately count did not change or in this case, the iterator
    would never stop. Hence, if your collection changes while you're iterating over it, you might get inexpected
    results. Writing to the same collection within the loop of the iterator is generally a bad idea...</p>

<p><strong>Advanced Features</strong></p>

<p>Since V2.2.5 the <em>Morphium</em> iterator supports lookahead (prefetching). This means its not only possible to
    define a window size to step through your data, but also how many of those windows should be prefetched, while you
    step through the first one.</p>

<p>This works totally transparent for the user, its just a simple call to activate this feature:</p>

<pre><code class="java">theQuery.asIterable(1000,5); //window size 1000, 5 windows prefetch
</code></pre>

<p>Since 2.2.5 the <em>Morphium</em> iterator is also able to be used by multiple threads simultaneously. This means,
    several threads access the <em>same</em> iterator. This might be useful for querying and alike.</p>

<p>To use that, you only need to set <code>setMultithreaddedAccess</code> to true in the iterator itself:</p>

<pre><code class="java">MorphiumIterator&lt;MyEntity&gt; it=theQuery.asIterable(1000,15)
it.setMultithreaddedAccess(true);
</code></pre>

<p><em>Attention</em>: Setting mutlithreaddedAccess to true will cause the iterator to be a bit slower as it has to do
    some things in a <code>synchronized</code> fashion.</p>

<h2 id="storing">Storing</h2>

<p>Storing is more or less a very simple thing, just call <code>_Morphium_.store(pojo)</code> and you're done. Although
    there is a bit more to it: - if the object does not have an id (id field is <code>null</code>), there will be a new
    entry into the corresponding collection. - if the object does have an id set (!= <code>null</code>), an update to db
    is being issued. - you can call <code>_Morphium_.storeList(lst)</code> where lst is a list of entities. These would
    be stored in bulkd, if possible. Or it does a bulk update of things in mongo. Even mixed lists (update and inserts)
    are possible. <em><em>Morphium</em></em> will take care of sorting it out - there are additional methods for writing
    to mongo, like update operations <code>set</code>, <code>unset</code>, <code>push</code>, <code>pull</code> and so
    on (update a value on one entity or for all elements matching a query), <code>delete</code> objects or objects
    matching a query, and a like - The writer that acutally writes the data, is chosen depending on the configuration of
    this entity (see Annotations below)</p>

<h3 id="names-of-entities-and-fields">Names of entities and fields</h3>

<p><em><em>Morphium</em></em> by defaults converts all java CamelCase identifiers in underscore separated strings. So,
    <code>MyEntity</code> will be stored in an collection called <code>my_entity</code> and the field
    <code>aStringValue</code> would be stored in as <code>a_string_value</code>.</p>

<p>When specifying a field, you can always use either the transformed name or the name of the corresponding java field.
    Collection names are always determined by the classname itself.</p>

<h4 id="camelcase-conversion">CamelCase conversion</h4>

<p>But in <em><em>Morphium</em></em> you can of course change that behaviour. Easiest way is to switch off the
    transformation of CamelCase globally by setting <code>camelCaseConversionEnabled</code> to false (see above:
    Configuration). If you switch it off, its off completely - no way to do switch it on for just one collection or so.
</p>

<p>If you need to have only several types converted, but not all, you have to have the conversion globally enabled, and
    only switch it off for certain types. This is done in either the <code>@Entity</code> or <code>@Embedded</code>
    annotation.</p>

<pre><code class="java">        @Entity(convertCamelCase=false)
        public class MyEntity {
             private String myField;
</code></pre>

<p>This example will create a collection called <code>MyEntity</code> (no conversion) and the field will be called
    <code>myField</code> in mongo as well (no conversion).</p>

<p><em>Attention</em>: Please keep in mind that, if you switch off camelCase conversion globally, nothing will be
    converted!</p>

<h4 id="using-the-full-qualified-classname">using the full qualified classname</h4>

<p>you can tell <em><em>Morphium</em></em> to use the full qualified classname as basis for the collection name, not the
    simple class name. This would result in createing a collection <code>de_caluga_morphium_my_entity</code> for a class
    called <code>de.caluga.morphium.MyEntity</code>. Just set the flag <code>useFQN</code> in the entity annotation to
    <code>true</code>.</p>

<pre><code class="java">        @Entity(useFQN=true)
        public class MyEntity {
</code></pre>

<p>Recommendation is, not to use the full qualified classname unless it's really needed.</p>

<h4 id="specifying-a-collection-fieldname">Specifying a collection / fieldname</h4>

<p>In addition to that, you can define custom names of fields and collections using the corresponding annotation (<code>@Entity</code>,
    <code>@Property</code>).</p>

<p>For entities you may set a custom name by using the <code>collectionName</code> value for the annotation:</p>

<pre><code class="java">        @Entity(collectionName=&quot;totallyDifferent&quot;)
        public class MyEntity {
            private String myValue;
        }
</code></pre>

<p>the collection name will be <code>totallyDifferent</code> in mongo. Keep in mind that camel case conversion for
    fields will still take place. So in that case, the field name would probably be <code>my_value</code>. (if camel
    case conversion is enabled in config)</p>

<p>You can also specify the name of a field using the property annotation:</p>

<pre><code class="java">        @Property(fieldName=&quot;my_wonderful_field&quot;)
        private String something;
</code></pre>

<p>Again, this only affects this field (in this case, it will be called <code>my_wondwerful_field</code> in mongo) and
    this field won't be converted camelcase. This might cause a mix up of cases in your MongoDB, so please use this with
    care.</p>

<h4 id="accessing-fields">Accessing fields</h4>

<p>When accessing fields in <em><em>Morphium</em></em> (especially for the query) you may use either the name of the
    Field in Java (like myEntity) or the converted name depending on the config (camelCased or not, or custom).</p>

<h4 id="using-nameproviders">Using NameProviders</h4>

<p>In some cases it might be necessary to have the collection name calculated dynamically. This can be achieved using
    the <code>NameProvider</code> Interface.</p>

<p>You can define a NameProvider for your entity in the <code>@Entity</code> annotation. You need to specify the type
    there. By default, the NameProvider for all Entities is <code>DefaultNameProvider</code>. Which actually looks like
    this:</p>

<pre><code class="java">public final class DefaultNameProvider implements NameProvider {
            
    @Override
    public String getCollectionName(Class&lt;?&gt; type, ObjectMapper om, boolean translateCamelCase, boolean useFQN, String specifiedName, _Morphium_ _Morphium_) {
    
        String name = type.getSimpleName();
    
        if (useFQN) {
            name = type.getName().replaceAll(&quot;\\.&quot;, &quot;_&quot;);
        }
        if (specifiedName != null) {
            name = specifiedName;
        } else {
            if (translateCamelCase) {
                name = _Morphium_.getARHelper().convertCamelCase(name);
            }
        }
        return name;
    }
}
</code></pre>

<p>You can use your own provider to calculate collection names depending on time and date or for example depending on
    the querying host name (like: create a log collection for each server separately or create a collection storing logs
    for only one month each).</p>

<p><strong>Attention</strong>: Name Provider instances will be cached, so please implement them thread safe.</p>

<h4 id="examples">examples</h4>

<p>mongo is really fast and stores a lot of date in no time. Sometimes it's hard then, to get this data out of mongo
    again, especially for logs this might be an issue (in our case, we had more than a 100 million entries in one
    collection). It might be a good idea to change the collection name upon some rule (by date, timestamp whatever you
    like). <em>Morphium</em> supports this using a strategy-pattern.</p>

<pre><code class="java">public class DatedCollectionNameProvider implements NameProvider{
    @Override
    public String getCollectionName(Class&lt;?&gt; type, ObjectMapper om, boolean translateCamelCase, boolean useFQN, String specifiedName, Morphium morphium) {
        SimpleDateFormat df=new SimpleDateFormat(&quot;yyyyMM&quot;);
        String date=df.format(new Date());
        String ret=null;
        if (specifiedName!=null) {
            ret=specifiedName+=&quot;_&quot;+date;
        } else {
                String name = type.getSimpleName();
                if (useFQN) {
                    name=type.getName();
                }
            if (translateCamelCase) {
                name=om.convertCamelCase(name);
            }
            ret=name+&quot;_&quot;+date;
        }
        return ret;
    }
}
</code></pre>

<p>This would create a monthly named collection like &quot;my_entity_201206&quot;. In order to use that name provider,
    just add it to your <code>@Entity</code>-Annotation:</p>

<pre><code class="java">@Entity(nameProvider = DatedCollectionNameProvider.class)
public class MyEntity {
....
}
</code></pre>

<p><strong>performance</strong>:</p>

<p>The name provider instances themselves are cached for each type upon first use, so you actually might do as much work
    as possible in the constructor. </p>

<p>BUT: on every read or store of an object the corresponding name provider method <code>getCollectionName</code> is
    called, this might cause Performance drawbacks, if you logic in there is quite heavy and/or time consuming.</p>

<h3 id="automatic-values">Automatic values</h3>

<p>This is something quite common: you want to know, when your data was last changed and maybe who did it. Usually you
    keep a timestamp with your object and you need to make sure, that these timestamps are updated accordingly. <em>Morphium</em>
    does this automatically - just declare the annotations:</p>

<pre><code class="java"> @Entity
    @NoCache
    @LastAccess
    @LastChange
    @CreationTime
    public static class TstObjLA {
        @Id
        private ObjectId id;

        @LastAccess
        private long lastAccess;

        @LastChange
        private long lastChange;

        @CreationTime
        private long creationTime;

        private String value;

        public long getLastAccess() {
            return lastAccess;
        }

        public void setLastAccess(long lastAccess) {
            this.lastAccess = lastAccess;
        }

        public long getLastChange() {
            return lastChange;
        }

        public void setLastChange(long lastChange) {
            this.lastChange = lastChange;
        }

        public long getCreationTime() {
            return creationTime;
        }

        public void setCreationTime(long creationTime) {
            this.creationTime = creationTime;
        }

        public String getValue() {
            return value;
        }

        public void setValue(String value) {
            this.value = value;
        }
    }
</code></pre>

<p>You might ask, why do we need to specify, that access time is to be stored for the class and the field. The reason
    is: Performance! In order to search for a certain annotation we need to read all fields of the whole hierarchy the
    of the corresponding object which is rather expensive. In this case, we only search for those access fields, if
    necessary. All those are stored as long - System.currentTimeMillies()</p>

<p><em>Explanation:</em></p>

<p><code>@LastAccess</code>: Stores the last time, this object was read from db! Careful with that one: it will create a
    write access, for <em>every read</em>!</p>

<p><code>@CreationTime</code>: Stores the creation timestamp</p>

<p><code>@LastChange</code>: Timestamp the last moment, this object was stored.</p>

<h2 id="asynchronous-api">Asynchronous API</h2>

<p>All writer implementation support asynchronous calls like</p>

<pre><code class="java">   public &lt;T&gt; void store(List&lt;T&gt; lst, AsyncOperationCallback&lt;T&gt; callback); 
</code></pre>

<p>if callback==null the method call should be synchronous... If callback!=null do the call to mongo asynchronous in
    background. Usually, you specify the default behaviour in your class definition:</p>

<pre><code class="java">  @Entity
  @AsyncWrites
  public class EntityType {
   ...
  }
</code></pre>

<p>All write operations to this type will be asynchronous! (synchronous call is not possible in this case!).</p>

<p>Asynchronous calls are also possible for Queries, you can call q.asList(callback) if you want to have this query be
    executed in background.</p>

<h3 id="difference-asynchronous-write-write-buffer">Difference asynchronous write / write buffer</h3>

<p>Asynchronous calls will be issued at once to the mongoDb but the calling thread will not have to wait. It will be
    executed in Background. the <code>@WriteBuffer</code> annotation specifies a write buffer for this type (you can
    specify the size etc if you like). All writes will be held temporarily in ram until time frame is reached or the
    number of objects in write buffer exceeds the maximum you specified (0 means no maximum). Attention if you shut down
    the Java VM during that time, those entries will be lost. Please only use that for logging or &quot;not so important&quot;
    data. specifying a write buffer four you entitiy is quite easy:</p>

<pre><code class="java">  @Entity
  @WriteBuffer(size=1000, timeout=5000)
  public class MyBufferedLog {
  ....
  }
</code></pre>

<p>This means, all write access to this type will be stored for 5 seconds or 1000 entries, whichever occurs first. If
    you want to specify a different behavior when the maximum number of entries is reached, you can specify a
    strategy:</p>

<ul>
    <li><code>WRITE_NEW</code>: write newest entry (synchronous and not add to buffer)</li>
    <li><code>WRITE_OLD</code>: write some old entries (and remove from buffer)</li>
    <li><code>DEL_OLD</code>: delete old entries from buffer - oldest elements won't be written to Mongo!</li>
    <li><code>IGNORE_NEW</code>: just ignore incoming - newest elements WILL NOT BE WRITTEN!</li>
    <li><code>JUST_WARN</code>: increase buffer and warn about it</li>
</ul>

<h2 id="validation-support">Validation support</h2>

<p>Morphium does support for javax.validation annotations and those might be used to ensure data quality:</p>

<pre><code class="java"> @Id
    private MorphiumId id;

    @Min(3)
    @Max(7)
    private int theInt;

    @NotNull
    private Integer anotherInt;

    @Future
    private Date whenever;

    @Pattern(regexp = &quot;m[ueü]nchen&quot;)
    private String whereever;

    @Size(min = 2, max = 5)
    private List friends;

    @Email
    private String email;
</code></pre>

<p>You do not need to have any validator implementation in classpath, <em>Morphium</em> detects, if validation is
    available and only enables it then.</p>

<h2 id="annotations">Annotations</h2>

<p>a lot of things can be configured in <em><em>Morphium</em></em> using annotations. Those annotations might be added
    to either classes, fields or both.</p>

<h3 id="entity">Entity</h3>

<p>Perhaps <em>the</em> most important Annotation, as it has to be put on every class the instances of which you want to
    have stored to database. (Your data objects).</p>

<p>By default, the name of the collection for data of this entity is derived by the name of the class itself and then
    the camel case is converted to underscore strings (unless config is set otherwise).</p>

<p>These are the settings available for entities:</p>

<ul>
    <li><code>translateCamelCase</code>: default true. If set, translate the name of the collection and all fields (only
        those, which do not have a custom name set)
    </li>
    <li><code>collectionName</code>: set the collection name. May be any value, camel case won't be converted.</li>
    <li><code>useFQN</code>: if set to true, the collection name will be built based on the full qualified class name.
        The Classname itself, if set to false. Default is false
    </li>
    <li><code>polymorph</code>: if set to true, all entities of this type stored to mongo will contain the full
        qualified name of the class. This is necessary, if you have several different entities stored in the same
        collection. Usually only used for polymorph lists. But you could store any polymorph marked object into that
        collection Default is false
    </li>
    <li><code>nameProvider</code>: specify the class of the name provider, you want to use for this entity. The name
        provider is being used to determine the name of the collection for this type. By Default it uses the <code>DefaultNameProvider</code>
        (which just uses the classname to build the collection name). see above
    </li>
</ul>

<h3 id="embedded">Embedded</h3>

<p>Marks POJOs for object mapping, but don't need to have an ID set. These objects will be marshalled and un-marshalled,
    but only as part of another object (Subdocument). This has to be set at class level.</p>

<p>You can switch off camel case conversion for this type and determine, whether data might be used polymorph.</p>

<h3 id="asyncwrites">AsyncWrites</h3>

<p>ensures, that all write accesses to this entity are asynchronous.</p>

<h3 id="nocache">NoCache</h3>

<p>switches OFF caching for this entity. This is useful if some superclass might have caches enabled and we need to
    disable it here.</p>

<h3 id="capped">Capped</h3>

<p>Valid at: Class level</p>

<p>Tells <em><em>Morphium</em></em> to create a capped collection for this object (see capped collections above).</p>

<p>Parameters:</p>

<ul>
    <li><em>maxSize</em>: maximum size in byte. Is used when converting to a capped collection</li>
    <li><em>maxNumber</em>: number of entries for this capped collection</li>
</ul>

<h3 id="collation">Collation</h3>

<p>These are the collation settings for this given entity. will be used when creating new collections and indices</p>

<h3 id="additionaldata">AdditionalData</h3>

<p>Special feature for <em><em>Morphium</em></em>: this annotation has to be added for at lease <em>one</em> field of
    type Map&lt;String,Object&gt;. It does make sure, that all data in Mongo, that cannot be mapped to a field of this
    entity, will be added to the annotated Map properties.</p>

<p>by default this map is read only. But if you want to change those values or add new ones to it, you can set <code>readOnly=false</code>.
</p>

<h3 id="aliases">Aliases</h3>

<p>It's possible to define aliases for field names with this annotation (hence it has to be added to a field).</p>

<pre><code class="java">@Alias({&quot;stringList&quot;,&quot;string_list&quot;})
List&lt;String&gt; strLst;
</code></pre>

<p>in this case, when reading an object from MongoDB, the name of the field <code>strLst</code> might also be <code>stringList</code>
    or <code>string_list</code> in mongo. When storing it, it will always be stored as <code>strLst</code> or <code>str_lst</code>
    according to configs camelcase settings.</p>

<p>This feature comes in handy when migrating data.</p>

<h3 id="creationtime">CreationTime</h3>

<p>has to be added to both the class and the field(s) to store the creation time in. This value is set in the moment,
    the object is being stored to mongo. The data type for creation time might be:</p>

<ul>
    <li><code>long</code> / <code>Long</code>: store as timestamp</li>
    <li><code>Date</code>: store as date object</li>
    <li><code>String</code>: store as a string, you may need to specify the format for that</li>
</ul>

<h3 id="lastaccess">LastAccess</h3>

<p>same as creation time, but storing the last access to this type. <strong>Attention</strong>: will cause all objects
    read to be updated and written again with a changed timestamp.</p>

<p>Usage: find out, which entries on a translation table are not used for quite some time. Either the translation is not
    necessary anymore or the corresponding page is not being used.</p>

<h3 id="lastchange">LastChange</h3>

<p>Same as the two above, except the timestamp of the last change (to mongo) is being stored. The value will be set,
    just before the object is written to mongo.</p>

<h3 id="defaultreadpreference">DefaultReadPreference</h3>

<p>Define the read preference level for an entity. This annotation has to be used at class level. Valid types are:</p>

<ul>
    <li><code>PRIMARY</code>: only read from primary node</li>
    <li><code>PRIMARY_PREFERED</code>: if possible, use primary.</li>
    <li><code>SECONDARY</code>: only read from secondary node</li>
    <li><code>SECONDARY_PREFERED</code>: if possible, use secondary</li>
    <li><code>NEAREST</code>: I don't care, take the fastest</li>
</ul>

<h3 id="id">Id</h3>

<p>Very important annotation to a field of every entity. It marks that field to be the id and identify any object. It
    will be stored as <code>_id</code> in mongo (and will get an index).</p>

<p>The Id may be of any type, though usage of ObjectId is strongly recommended.</p>

<h3 id="index">Index</h3>

<p>Define indexes. Indexes can be defined for a single field. Combined indexes need to be defined on class level. See
    above.</p>

<h3 id="ignorefields">IgnoreFields</h3>

<p>List of fields in class, that can be ignored. Defaults no none.</p>

<p>usually an exact match, but can use ~ as substring, / as regex marker</p>

<p>Field names are JAVA Fields, not translated ones for mongo</p>

<p><code>IgnoreFields</code> will not be honored for fields marked with <code>@Property</code> and a custom fieldname
</p>

<p>this will be inherited by subclasses!</p>

<pre><code class="java"> 
    @Entity
    @IgnoreFields({&quot;var1&quot;, &quot;var3&quot;})
    public class TestClass {
        @Id
        public MorphiumId id;
        public int var1;
        public int var2;
        public int var3;
    }
</code></pre>

<h3 id="limittofields">LimitToFields</h3>

<p>this is a positive list of fields to use for MongoDB. All fields, not listed here will be ignored when it comes to
    mongodb.</p>

<pre><code class="java"> @Entity
    @LimitToFields({&quot;var1&quot;})
    public class TestClass2 {
        @Id
        public MorphiumId id;
        public int var1;
        public int var2;
        public int var3;
    }
</code></pre>

<p><code>LimitToFields</code> also takes a Class as an argument, then the fields will be limited to the fields of the
    given class.</p>

<pre><code class="java">
    @Entity
    @LimitToFields(type = TestClass2.class)
    public class TestClass3 extends TestClass2 {

        public String notValid;
    }

</code></pre>

<h3 id="property">Property</h3>

<p>Can be added to any field. This not only has documenting character, it also gives the opportunity to change the name
    of this field by setting the <code>fieldName</code> value. By Default the fieldName is &quot;.&quot;, which means
    &quot;fieldName based&quot;.</p>

<h3 id="readonly">ReadOnly</h3>

<p>Mark an entity to be read only. You'll get an exception when trying to store.</p>

<h3 id="version">Version</h3>

<p>Mark a field to keep the current Version number. Field needs to be of type Long!</p>

<h3 id="reference">Reference</h3>

<p>If you have a member variable, that is a POJO and not a simple value, you can store it as reference to a different
    collection, if the POJO is an Entity (and only if!).</p>

<p>This also works for lists and Maps. Attention: when reading Objects from disk, references will be de-referenced,
    which will result into one call to mongo each.</p>

<p>Unless you set <code>lazyLoading</code> to true, in that case, the child documents will only be loaded when accessed.
</p>

<h4 id="lazy-loaded-references">Lazy Loaded references</h4>

<p><em>Morphium</em> supports lazy loading of references. This is easy to use, just add <code>@Reference(lazyLoading=true)</code>
    to the reference you want to have them loaded lazyly.</p>

<pre><code class="java">@Entity
public class MyEntity {
   ....
   @Reference(lazyLoading=true)
   private UncachedObject myReference;  //will be loaded when first accessed
   @Reference
   private MyEntity ent; //will be loaded when this object is loaded - use with caution
                         //this could cause an endless loop
   private MyEntity embedded; //this object is not available on its own
                              //its embedded as subobject in this one
}
</code></pre>

<p>When a reference is being lazy loaded, the corresponding field will be set with a Proxy for an instance of the
    correct type, where only the ObjectID is set. Any access to it will be catched by the proxy, and any method will
    cause the object to be read from DB and deserialized. Hence this object will only be loaded upon first access.</p>

<p>It should be noted that when using <code>Object.toString();</code> for testing that the object will be loaded from
    the database and appear to not be lazy loaded. In order to test Lazy Loading you should load the base object with
    the lazy reference and access it directly and it will be null. Additionally the referenced object will be null until
    the references objects fields are accessed.</p>

<h3 id="transient">Transient</h3>

<p>Do not store the field - similar to <code>@IgnoreFields</code> or <code>@LimitToFields</code></p>

<h3 id="cache">Cache</h3>

<p>Cache settings for this entity, see the chapter about transparent caching above for more details.</p>

<h3 id="encrypted">Encrypted</h3>

<p>Encryption settings for this field. See chapter about field encryption for details</p>

<h3 id="useifnull">UseIfNull</h3>

<p>Usually, <em>Morphium</em> does not store null values. That means, the corresponding document just would not contain
    the given field(s) at all.</p>

<p>Sometimes that might cause problems, so if you add <code>@UseIfNull</code> to any field, it will be stored into mongo
    even if it is null.</p>

<h3 id="lifecycle">LifeCycle</h3>

<p>this annotation for an Entity tells morphium, that this entity does have some lifecycle methods defined. Those
    methods all need to be marked with the corresponding annotation:</p>

<ul>
    <li><code>@PostLoad</code></li>
    <li><code>@PostRemove</code></li>
    <li><code>@PostStore</code></li>
    <li><code>@PostUpdate</code></li>
    <li><code>@PreRemove</code> - may throw a <code>MorphiumAccessVetoException</code> to abort the removal</li>
    <li><code>@PreStore</code> - may throw a <code>MorphiumAccessVetoException</code> to abort store</li>
    <li><code>@PreUpdate</code> - may throw a <code>MorphiumAccessVetoException</code> to abort update</li>
</ul>

<p>the methods where those annotations are added must not have any parameters. They should only access the local
    object/entity.</p>

<h3 id="version">Version</h3>

<p>only used auto-versioning is enabled in <code>@Entity</code>. Defines the field to hold the version number.</p>

<h3 id="writesafety">WriteSafety</h3>

<p>Specify the safety for this entity when it comes to writing to mongo. This can range from &quot;NONE&quot; to &quot;WAIT
    FOR ALL SLAVES&quot;. Here are the available settings:</p>

<ul>
    <li>timeout: set a timeout in ms for the operation - if set to 0, unlimited (default). If set to negative value,
        wait relative to replication lag
    </li>
    <li>level: set the safety level:

        <ul>
            <li><code>IGNORE_ERRORS</code> None, no checking is done</li>
            <li><code>NORMAL</code> None, network socket errors raised</li>
            <li><code>BASIC</code> Checks server for errors as well as network socket errors raised</li>
            <li><code>WAIT_FOR_SLAVE</code> Checks servers (at lease 2) for errors as well as network socket errors
                raised
            </li>
            <li><code>MAJORITY</code> Wait for at least 50% of the slaves to have written the data</li>
            <li><code>WAIT_FOR_ALL_SLAVES</code>: waits for all slaves to have committed the data. This is depending on
                how many slaves are available in replica set. Wise timeout settings are important here. See WriteConcern
                in MongoDB Java-Driver for additional information
            </li>
        </ul>
    </li>
</ul>

<h4 id="cluster-awareness">Cluster awareness</h4>

<p><em>Morphium</em> is tracking the cluster status internally in order to react properly on different scenarios<sup><a
        class="footnote" href="#fn6-7368" id="fnr6-7368" title="see footnote">6</a></sup>. For example, if one node goes
    down, waiting for all nodes to write the data will result in the application blocking until the last cluster member
    came back up again.</p>

<p>This is defined by the <code>w</code>-Setting in <code>WriteSafety</code>. In a nutshell, it tells mongo on how many
    cluster nodes you want to have written, and will wait until this number is reached.</p>

<p>This caused <em>major</em> problems with our environments, like having different cluster configurations in test and
    production environments. </p>

<p><em>Morphium</em> fixes that issue in that way, that when &quot;WAIT_FOR_ALL_SLAVES&quot; is defined in <code>WriteSafety</code>,
    it will set the <code>w</code>-value according to the number of <em>available</em> slaves, resulting in no blocking.
    <sup><a class="footnote" href="#fn7-7368" id="fnr7-7368" title="see footnote">7</a></sup></p>

<h3 id="annotation-inheritance">Annotation Inheritance</h3>

<p>By default, Java does not support the inheritance of annotations. This is ok in most cases, but in the case of
    entities it's a bugger. We added inheritance to <em>Morphium</em> to be able to build flexible data structures and
    store them to mongo.</p>

<h3 id="implementation">Implementation</h3>

<p>Well, it's quite easy, actually ;-) The algorithm for getting the inherited annotations looks as follows
    (simplified)</p>

<ol>
    <li>Take the annotations from the current class, if found, return it</li>
    <li>Take the superclass, if superclass is &quot;Object&quot; return null</li>
    <li>if there is the annotation to look for, return it</li>
    <li>continue with step 1</li>
</ol>

<p>This way, all annotations in the hierarchy are taken into account and the most recent one is taken. You can always
    change the annotations when subclassing, although you cannot &quot;erase&quot; them (which means, if you inherit
    from an entity, it's always an entity). For Example:</p>

<pre><code class="java">   @Entity 
   @NoCache
   public class Person {
      @Id
      private ObjectId id;
     ....
   }
</code></pre>

<p>And the subclass:</p>

<pre><code class="java">   @Cache(writeCache=true, readCache=false)
   public class Parent {
      @Reference
      private List&lt;Person&gt; parentFrom;
      ...
   }
</code></pre>

<p>Please keep in mind, that unless specified otherwise, the classname will be taken as the name for your collection.
    Also, be sure to store your classname in the collection (set polymorph=true in @Entity annotation) if you want to
    store them in one collection.</p>

<h2 id="changestream-support">Changestream support</h2>

<p>MongoDB introduced a feature called changestreams with V4.0 of mongodb. This is a special search that returns all
    changes to a database or collection. This is very useful if you want to be notified about changes to certain types
    or about certain commands being run.</p>

<p>Changestreams are only available when connected to a replicaset.</p>

<p><em>Morphium</em> does support changestreams, in fact the messaging subsystem is built completely relying on this
    feature.</p>

<p>The easiest way to use changestreams is to use <em>Morphiums</em> <code>ChangeStreamMonitor</code>:</p>

<pre><code class="java">ChangeStreamMonitor m = new ChangeStreamMonitor(morphium, UncachedObject.class);
m.start();
final AtomicInteger cnt = new AtomicInteger(0);

m.addListener(evt -&gt; {
    printevent(evt);
    cnt.set(cnt.get() + 1);
    return true;
});
Thread.sleep(1000);
for (int i = 0; i &lt; 100; i++) {
    morphium.store(new UncachedObject(&quot;value &quot; + i, i));
}
Thread.sleep(5000);
m.terminate();
assert (cnt.get() &gt;= 100 &amp;&amp; cnt.get() &lt;= 101) : &quot;count is wrong: &quot; + cnt.get();
morphium.store(new UncachedObject(&quot;killing&quot;, 0));

</code></pre>

<p>The monitor by definition runs asynchronous, it uses the <code>watch</code> methods to database or collection. </p>

<ul>
    <li><code>morphium.watch(Class type, boolean updateFullDocument,ChangeStreamListener lst)</code>: this watches in a
        <em>synchronous</em> call for any change event. This call <em>blocks!</em> until the Listener returns <code>false</code>
    </li>
    <li><code>morphium.watchAsync(...)</code> (same parameters as above), runs asynchronously. <em>attention</em>: the
        Settings for asyncExcecutor in <code>MorphiumConfig</code> might affect the behaviour of this call.
    </li>
</ul>

<p>There are also methods for watching <em>all</em> changes, that happen in the connected database. This might result in
    a lot of callbacks: <code>watchDB()</code> and <code>watchDBAsync()</code>.</p>

<h4 id="oplogmonitor">OplogMonitor</h4>

<p>there is also an older implementation of this, the <code>OplogMonitor</code>. This one does more or less the same
    thing as the <code>ChangeStreamMonitor</code>, but also runs with older installations of MongoDB (when connected to
    a ReplicaSet).</p>

<p>You'd probably want to use the <code>ChangestreamListener</code> instead, as it is more efficient. </p>

<pre><code class="java">OplogListener lst = data -&gt; {
            log.info(Utils.toJsonString(data));
            gotIt = true;
        };
        OplogMonitor olm = new OplogMonitor(morphium);
        olm.addListener(lst);
        olm.start();

        Thread.sleep(100);
        UncachedObject u = new UncachedObject(&quot;test&quot;, 123);
        morphium.store(u);

        Thread.sleep(1250);
        assert (gotIt);
        gotIt = false;

        morphium.set(u, UncachedObject.Fields.value, &quot;new value&quot;);
        Thread.sleep(550);
        assert (gotIt);
        gotIt = false;

        olm.removeListener(lst);
        u = new UncachedObject(&quot;test&quot;, 123);
        morphium.store(u);
        Thread.sleep(200);
        assert (!gotIt);


        olm.stop();
</code></pre>

<h3 id="partial-updating">partial updating</h3>

<p>The idea behind partial updates is, that only the changes to an entity are transmitted to the database and will thus
    reduce the load on network and MongoDB itself. </p>

<p>This is the easiest way - you already know, what fields you changed and maybe you even do not want to store fields,
    that you actually did change. In that case, call the updateUsingFields-Method:</p>

<pre><code class="java">   UncachedObject o....
   o.setValue(&quot;A value&quot;);
   o.setCounter(105);
   Morphium.get().updateUsingFields(o,&quot;value&quot;); 
         //does only send updates for Value to mongodb
         //counter is ignored
</code></pre>

<p><code>updateUsingFields()</code> honours the lifecycle methods as well as caches (write cache or clear read_cache on
    write). take a look at some code from the corresponding JUnit test for better understanding:</p>

<pre><code class="java">UncachedObject o... //read from MongoDB
o.setValue(&quot;Updated!&quot;);
morphium.updateUsingFields(o, &quot;value&quot;);
log.info(&quot;uncached object altered... look for it&quot;);
Query&lt;UncachedObject&gt; c=morphium.createQueryFor(UncachedObject.class);
UncachedObject fnd= (UncachedObject) c.f(&quot;_id&quot;).eq( o.getMongoId()).get();
assert(fnd.getValue().equals(&quot;Updated!&quot;)):&quot;Value not changed? &quot;+fnd.getValue();
</code></pre>

<h3 id="bulkrequest-support">BulkRequest support</h3>

<p>If you need to send a lot of write requests to MongoDB, it might be useful to use <em>bulk requests</em> for that.
    MongoDB does have support for that. It means, that not each command is sent on its own, but all are sent in one
    single bulk command to the database, which is a lot more efficient.</p>

<p>To use that via <em>Morphium</em> you need to add your requests to the <code>BulkRequestContext</code>:</p>

<pre><code class="java">MorphiumBulkContext c = morphium.createBulkRequestContext(UncachedObject.class, false);
c.addSetRequest(morphium.createQueryFor(UncachedObject.class).f(&quot;counter&quot;).gte(0), &quot;counter&quot;, 999, true, true);
//could add more requests here
Map&lt;String, Object&gt; ret = c.runBulk();
</code></pre>

<p>There are all basic operations you might send in a bulk:</p>

<ul>
    <li>insert</li>
    <li>delete</li>
    <li>set/unset</li>
    <li>inc/dec</li>
    <li>update</li>
    <li>mul (multiplication)</li>
    <li>...</li>
</ul>

<p>If there is a special request, where there is no direct support in bulk context, use the generic method <code>addCustomUpdateRequest()</code>
    for adding a request. You need to pass on your requests Map-Representation.</p>

<h3 id="transaction-support">Transaction support</h3>

<p>MongoDB does have support for transactions in newer releases. <em>Morphium</em> does support that as well:</p>

<pre><code class="java">  @Test
    public void transactionTest() throws Exception {
        for (int i = 0; i &lt; 10; i++) {
            try {
                morphium.createQueryFor(UncachedObject.class).delete();
                Thread.sleep(100);
                TestEntityNameProvider.number.incrementAndGet();
                log.info(&quot;Entityname number: &quot; + TestEntityNameProvider.number.get());
                createUncachedObjects(10);
                Thread.sleep(100);


                morphium.startTransaction();
                Thread.sleep(100);
                log.info(&quot;Count after transaction start: &quot; + morphium.createQueryFor(UncachedObject.class).countAll());
                UncachedObject u = new UncachedObject(&quot;test&quot;, 101);
                morphium.store(u);
                Thread.sleep(100);
                long cnt = morphium.createQueryFor(UncachedObject.class).countAll();
                if (cnt != 11) {
                    morphium.abortTransaction();
                    assert (cnt == 11) : &quot;Count during transaction: &quot; + cnt;
                }

                morphium.inc(u, &quot;counter&quot;, 1);
                Thread.sleep(100);
                u = morphium.reread(u);
                assert (u.getCounter() == 102);
                morphium.abortTransaction();
                Thread.sleep(100);
                cnt = morphium.createQueryFor(UncachedObject.class).countAll();
                u = morphium.reread(u);
                assert (u == null);
                assert (cnt == 10) : &quot;Count after rollback: &quot; + cnt;
            } catch (Exception e) {
                log.error(&quot;ERROR&quot;, e);
                morphium.abortTransaction();
            }
        }

    }
</code></pre>

<p>Internally, <em>Morphium</em> uses the transaction context if <em>this thread</em> started a transaction (if you need
    a transaction spanning over Threads, you need to pass on the current transaction session:</p>

<pre><code class="java">ctx=morphium.getDriver().getTransactionContext();
...
//other thread
morphium.getDriver().setTransactionContext(ctx);
</code></pre>

<p><strong>Caveat</strong>: mongoDB does not support nested transactions (yet), so you will get an
    <code>Exception</code> when trying to start another transaction in the same thread.</p>

<h2 id="listeners-in-morphium">Listeners in <em>Morphium</em></h2>

<p>there are a lot of listeners in <em>Morphium</em> that help you get informed about what is going on in the system.
    Some of which also might help you, to adapt behaviour according to your needs:</p>

<h3 id="replicasetstatuslistener">ReplicasetStatusListener</h3>

<p><em>Morphium</em> is monitoring the status of the replicaset it is connected to (default is every 5s, but can be
    changed in MorphiumConfigs setting <code>replicaSetMonitoringTimeout</code>). You can get this information on
    demand, by calling <code>morphium.getReplicasetStatus()</code>.</p>

<p>But you can also be informed whenever there is a change in the cluster by implementing the interface (since <em>Morphium</em>
    V4.2):</p>

<pre><code class="java">public interface ReplicasetStatusListener {

     void gotNewStatus(Morphium morphium, ReplicaSetStatus status);

    /**
     * infoms, if replicaset status could not be optained.
     * @param numErrors - how many errors getting the status in a row we already havei
     */
    void onGetStatusFailure(Morphium morphium, int numErrors);

    /**
     * called, if the ReplicasetMonitor aborts due to too many errors
     * @param numErrors - number of errors occured
     */
    void onMonitorAbort(Morphium morphium, int numErrors);

    /**
     *
     * @param hostsDown - list of hostnamed not up
     * @param currentHostSeed - list of currently available replicaset members
     */
    void onHostDown(Morphium morphium, List&lt;String&gt; hostsDown,List&lt;String&gt; currentHostSeed);
}
</code></pre>

<p>The <code>ReplicasetStatus</code> does contain a lot of information about the replicaset itself:</p>

<pre><code class="java">public class ReplicaSetStatus {
    private String set;
    private String myState;
    private String syncSourceHost;
    private Date date;
    private int term;
    private int syncSourceId;
    private long heartbeatIntervalMillis;
    private int majorityVoteCount;
    private int writeMajorityCount;
    private int votingMembersCount;
    private int writableVotingMembersCount;
    private long lastStableRecoveryTimestamp;
    private List&lt;ReplicaSetNode&gt; members;
    private Map&lt;String,Object&gt; optimes;
    private Map&lt;String,Object&gt; electionCandidateMetrics;
}


public class ReplicaSetNode {
    private int id;
    private String name;
    private double health;
    private int state;
    @Property(fieldName = &quot;stateStr&quot;)
    private String stateStr;
    private long uptime;
    @Property(fieldName = &quot;optimeDate&quot;)
    private Date optimeDate;

    @Property(fieldName = &quot;lastHeartbeat&quot;)
    private Date lastHeartbeat;
    private int pingMs;
    private String syncSourceHost;
    private int syncSourceId;
    private String infoMessage;
    private Date electionDate;
    private int configVersion;
    private int configTerm;
    private String lastHeartbeatMessage;
    private boolean self;
}

</code></pre>

<p>See mongoDB documentation of <a
        href="https://docs.mongodb.com/manual/reference/method/rs.status/"><code>rs.status()</code> command</a> for more
    information on the different fields.</p>

<h2 id="cachelistener">CacheListener</h2>

<p>Via this interface, you will be informed about cache operations and may interfere with them or change the
    behaviour:</p>

<pre><code class="java">public interface CacheListener {
    /**
     * ability to alter cached entries or avoid caching overall
     *
     * @param toCache - datastructure containing cache key and result
     * @param &lt;T&gt;     - the type
     * @return false, if not to cache
     */
     //return the cache entry to be stored, null if not
    &lt;T&gt; CacheEntry&lt;T&gt; wouldAddToCache(Object k, CacheEntry&lt;T&gt; toCache, boolean updated);

        //return false, if you do not want cache to be cleared
    &lt;T&gt; boolean wouldClearCache(Class&lt;T&gt; affectedEntityType);

        //return false, if you do not want entry to be removed from cache
    &lt;T&gt; boolean wouldRemoveEntryFromCache(Object key, CacheEntry&lt;T&gt; toRemove, boolean expired);

}
</code></pre>

<h3 id="cachesynclistener">CacheSyncListener</h3>

<p>This are special cache listeners which will be informed, when a cache needs to be updated because of incoming clear
    or update requests. There are two direct sub-interfaces:</p>

<ul>
    <li><code>WatchingCacheSyncListener</code>: to be used with <code>WatchingCacheSynchronizer</code></li>
    <li><code>MessagingCacheSyncListener</code>: to be used with <code>MessagingCacheSynchronizer</code></li>
</ul>

<p>The base interface is CacheSyncListener:</p>

<pre><code class="java">public interface CacheSyncListener {
    /**
     * before clearing cache - if cls == null whole cache
     * Message m contains information about reason and stuff...
     */
    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void preClear(Class cls) throws CacheSyncVetoException;

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void postClear(Class cls);
}
</code></pre>

<p>and the subclasses <code>WatchingCacheSyncListener</code> (just adds one other method):</p>

<pre><code class="java">public interface WatchingCacheSyncListener extends CacheSyncListener {
    void preClear(Class&lt;?&gt; type, String operation);

}
</code></pre>

<p>and the <code>MessagingCacheSyncListener</code> which adds some Messaging based methods:</p>

<pre><code class="java">public interface MessagingCacheSyncListener extends CacheSyncListener {

    /**
     * Class is null for CLEAR ALL
     *
     * @param cls
     * @param m   - message about to be send - add info if necessary!
     * @throws CacheSyncVetoException
     */
    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void preSendClearMsg(Class cls, Msg m) throws CacheSyncVetoException;

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void postSendClearMsg(Class cls, Msg m);
}

</code></pre>

<h3 id="changestreamlistener">ChangeStreamListener</h3>

<p>As already mentioned, this listener is used to be informed about changes in your data.</p>

<pre><code class="java">public interface ChangeStreamListener {
    /**
     * return true, if you want to continue getting events.
     *
     * @param evt
     * @return
     */
    boolean incomingData(ChangeStreamEvent evt);
}
</code></pre>

<h3 id="messagelistener">MessageListener</h3>

<p>This one is one of the core functionalities of <em>Morphium</em> messaging, this is the placed to be informed about
    incoming messages:</p>

<pre><code class="java">public interface ChangeStreamListener {
    /**
     * return true, if you want to continue getting events.
     *
     * @param evt
     * @return
     */
    boolean incomingData(ChangeStreamEvent evt);
}
</code></pre>

<h3 id="morphiumstoragelistener">MorphiumStorageListener</h3>

<p>If you add a listener for these kind of events, you will be informed about <em>any</em> store via morphium. This is
    kind of the same thing as the <code>LifeCycle</code> annotation and the corresponding methods. But its a different
    design pattern. If a <code>MorphiumAccessVetoException</code> is thrown, the corresponding action is aborted.</p>

<pre><code class="java">public interface MorphiumStorageListener&lt;T&gt; {
    void preStore(Morphium m, T r, boolean isNew) throws MorphiumAccessVetoException;

    void preStore(Morphium m, Map&lt;T, Boolean&gt; isNew) throws MorphiumAccessVetoException;

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void postStore(Morphium m, T r, boolean isNew);

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void postStore(Morphium m, Map&lt;T, Boolean&gt; isNew);

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void preRemove(Morphium m, Query&lt;T&gt; q) throws MorphiumAccessVetoException;

    @SuppressWarnings({&quot;EmptyMethod&quot;, &quot;UnusedParameters&quot;})
    void preRemove(Morphium m, T r) throws MorphiumAccessVetoException;

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void postRemove(Morphium m, T r);

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void postRemove(Morphium m, List&lt;T&gt; lst);

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void postDrop(Morphium m, Class&lt;? extends T&gt; cls);

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void preDrop(Morphium m, Class&lt;? extends T&gt; cls) throws MorphiumAccessVetoException;

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void postRemove(Morphium m, Query&lt;T&gt; q);

    @SuppressWarnings({&quot;EmptyMethod&quot;, &quot;UnusedParameters&quot;})
    void postLoad(Morphium m, T o);

    @SuppressWarnings({&quot;EmptyMethod&quot;, &quot;UnusedParameters&quot;})
    void postLoad(Morphium m, List&lt;T&gt; o);

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void preUpdate(Morphium m, Class&lt;? extends T&gt; cls, Enum updateType) throws MorphiumAccessVetoException;

    @SuppressWarnings(&quot;UnusedParameters&quot;)
    void postUpdate(Morphium m, Class&lt;? extends T&gt; cls, Enum updateType);

    enum UpdateTypes {
        SET, UNSET, PUSH, PULL, INC, @SuppressWarnings(&quot;unused&quot;)DEC, MUL, MIN, MAX, RENAME, POP, CURRENTDATE, CUSTOM,
    }

}
</code></pre>

<h3 id="oploglistener">OplogListener</h3>

<p>there is a listener / watch functionality that works with older Mongodb installations. The OpLogListener is used by
    the <code>OplogMonitor</code> and uses the OpLog to inform about changes <sup><a class="footnote" href="#fn8-7368"
                                                                                     id="fnr8-7368"
                                                                                     title="see footnote">8</a></sup>.
</p>

<pre><code class="java">public interface OplogListener {
    void incomingData(Map&lt;String, Object&gt; data);
}
</code></pre>

<h3 id="profiling-listener">Profiling Listener</h3>

<p>If you need to gather performance data about your mongoDB setup, the Profiling listener has you covered. It gives
    detailed information about the duration of any write or read access:</p>

<pre><code class="java">public interface ProfilingListener {
    void readAccess(Query query, long time, ReadAccessType t);

    void writeAccess(Class type, Object o, long time, boolean isNew, WriteAccessType t);
}
</code></pre>

<h2 id="the-aggregation-framework">The Aggregation Framework</h2>

<p>The aggregation framework is a very powerful feature of MongoDB and <em>Morphium</em> supports it from the start<sup><a
        class="footnote" href="#fn9-7368" id="fnr9-7368" title="see footnote">9</a></sup>. But with <em>Morphium</em>
    V4.2.x we made use of it a lot easier.</p>

<p>Core of the aggregation Framework in <em>Morphium</em> is the <code>Aggregator</code>. This will be created (using
    the configured <code>AggregatorFactory</code>) by a <code>Morphium</code> instance.</p>

<pre><code class="java">Aggregator&lt;Source,Result&gt; aggregator=morphium.createAggregator(Source.class,Result.class);
</code></pre>

<p>This creates an aggregator that reads from the entity <code>Source</code> (or better the corresponding collection)
    and returns the results in <code>Result</code>. Usually you will have to define a <code>Result</code> entity in
    order to use aggregation, but with <em>Morphium</em> V4.2 it is possible to have a <code>Map</code> as a result
    class.</p>

<p>After preparing the aggregator, you need to define the stages. All currently available stages are also available in
    <em>Morphium.</em> For a list of available stages, just consult the <a
            href="https://docs.mongodb.com/manual/core/aggregation-pipeline/">mongodb documentation</a>. </p>

<p>In a nutshell, the aggregation framework runs all documents through a pipeline of commands, that either reduce the
    input (like a query), change the output (a projection) or calculate some values (like with sum count etc). </p>

<p>The most important pipeline stage is probably the &quot;group&quot; stage. This is similar to the <code>group
    by</code> in SQL, but more powerful, as you can have several of those <code>group stages</code> in a pipeline.</p>

<p>here an Example with a simple pipeline:</p>

<pre><code class="java">Aggregator&lt;UncachedObject, Aggregate&gt; a = morphium.createAggregator(UncachedObject.class, Aggregate.class);
assertNotNull(a.getResultType());;
//reduce input
a = a.project(&quot;counter&quot;);
//Filter
a = a.match(morphium.createQueryFor(UncachedObject.class)
      .f(&quot;counter&quot;).gt(100));
//Sort, used with $first/$last
a = a.sort(&quot;counter&quot;);
//limit data
a = a.limit(15);
//group by - here we only have one static group, but could be any field or value
a = a.group(&quot;all&quot;).avg(&quot;schnitt&quot;, &quot;$counter&quot;).sum(&quot;summe&quot;, &quot;$counter&quot;).sum(&quot;anz&quot;, 1).last(&quot;letzter&quot;, &quot;$counter&quot;).first(&quot;erster&quot;, &quot;$counter&quot;).end();

//result projection
HashMap&lt;String, Object&gt; projection = new HashMap&lt;&gt;();
projection.put(&quot;summe&quot;, 1);
projection.put(&quot;anzahl&quot;, &quot;$anz&quot;);
projection.put(&quot;schnitt&quot;, 1);
projection.put(&quot;last&quot;, &quot;$letzter&quot;);
projection.put(&quot;first&quot;, &quot;$erster&quot;);
a = a.project(projection);

List&lt;Aggregate&gt; lst = a.aggregate();
assert (lst.size() == 1) : &quot;Size wrong: &quot; + lst.size();
log.info(&quot;Sum  : &quot; + lst.get(0).getSumme());
log.info(&quot;Avg  : &quot; + lst.get(0).getSchnitt());
log.info(&quot;Last :    &quot; + lst.get(0).getLast());
log.info(&quot;First:   &quot; + lst.get(0).getFirst());
log.info(&quot;count:  &quot; + lst.get(0).getAnzahl());


assert (lst.get(0).getAnzahl() == 15) : &quot;did not find 15, instead found: &quot; + lst.get(0).getAnzahl();
</code></pre>

<p>But you could have that result grouped again for example or add fields to it or change values or ....</p>

<p>Consult the MongoDB documentation for more information about the aggregation pipeline.</p>

<h3 id="aggregation-expressions">Aggregation Expressions</h3>

<p>MongoDB has support for an own expression language, that is mainly used in aggregation. _Morphium_s representation
    thereof is <code>Expr</code>. </p>

<p><code>Expr</code> does have a lot of factory methods to create special <code>Expr</code> instances, for example
    <code>Expr.string()</code> returns a string expression (string constant), <code>Expr.gt()</code> creates the &quot;greater
    than&quot; expression and so on.</p>

<p>Examples of expressions:</p>

<pre><code class="java">Expr e = Expr.add(Expr.field(&quot;the_field&quot;), Expr.abs(Expr.field(&quot;test&quot;)), Expr.doubleExpr(128.0));
Object o = e.toQueryObject();
String val = Utils.toJsonString(o);
log.info(val);
assert(val.equals(&quot;{ \&quot;$add\&quot; :  [ \&quot;$the_field\&quot;, { \&quot;$abs\&quot; :  [ \&quot;$test\&quot;] } , 128.0] } &quot;));

e = Expr.in(Expr.doubleExpr(1.2), Expr.arrayExpr(Expr.intExpr(12), Expr.doubleExpr(1.2), Expr.field(&quot;testfield&quot;)));
val=Utils.toJsonString(e.toQueryObject());
log.info(val);
assert(val.equals(&quot;{ \&quot;$in\&quot; :  [ 1.2,  [ 12, 1.2, \&quot;$testfield\&quot;]] } &quot;));

e = Expr.zip(Arrays.asList(Expr.arrayExpr(Expr.intExpr(1), Expr.intExpr(14)), Expr.arrayExpr(Expr.intExpr(1), Expr.intExpr(14))), Expr.bool(true), Expr.field(&quot;test&quot;));
val=Utils.toJsonString(e.toQueryObject());
log.info(val);
assert(val.equals(&quot;{ \&quot;$zip\&quot; : { \&quot;inputs\&quot; :  [  [ 1, 14],  [ 1, 14]], \&quot;useLongestLength\&quot; : true, \&quot;defaults\&quot; : \&quot;$test\&quot; }  } &quot;));

e = Expr.filter(Expr.arrayExpr(Expr.intExpr(1), Expr.intExpr(14), Expr.string(&quot;asV&quot;)), &quot;str&quot;, Expr.string(&quot;NEN&quot;));
val=Utils.toJsonString(e.toQueryObject());
log.info(val);
assert(val.equals(&quot;{ \&quot;$filter\&quot; : { \&quot;input\&quot; :  [ 1, 14, \&quot;asV\&quot;], \&quot;as\&quot; : \&quot;str\&quot;, \&quot;cond\&quot; : \&quot;NEN\&quot; }  } &quot;));
</code></pre>

<p>the output of this little program would be:</p>

<pre><code class="java">{ &quot;$add&quot; :  [ &quot;$the_field&quot;, { &quot;$abs&quot; :  [ &quot;$test&quot;] } , 128.0] } 
{ &quot;$in&quot; :  [ 1.2,  [ 12, 1.2, &quot;$testfield&quot;]] } 
{ &quot;$zip&quot; : { &quot;inputs&quot; :  [  [ 1, 14],  [ 1, 14]], &quot;useLongestLength&quot; : true, &quot;defaults&quot; : &quot;$test&quot; }  } 
{ &quot;$filter&quot; : { &quot;input&quot; :  [ 1, 14, &quot;asV&quot;], &quot;as&quot; : &quot;str&quot;, &quot;cond&quot; : &quot;NEN&quot; }  } 
</code></pre>

<p>This way you can create complex aggregation pipelines:</p>

<pre><code class="java">     Aggregator&lt;UncachedObject, Aggregate&gt; a = morphium.createAggregator(UncachedObject.class, Aggregate.class);
            assertNotNull(a.getResultType());;
            a = a.project(UtilsMap.of(&quot;counter&quot;, (Object) Expr.intExpr(1)).add(&quot;cnt2&quot;, Expr.field(&quot;counter&quot;)));
            a = a.match(Expr.gt(Expr.field(&quot;counter&quot;), Expr.intExpr(100)));
            a = a.sort(&quot;counter&quot;);
            a = a.limit(15);
            a = a.group(Expr.string(null)).expr(&quot;schnitt&quot;, Expr.avg(Expr.field(&quot;counter&quot;))).expr(&quot;summe&quot;, Expr.sum(Expr.field(&quot;counter&quot;))).expr(&quot;anz&quot;, Expr.sum(Expr.intExpr(1))).expr(&quot;letzter&quot;, Expr.last(Expr.field(&quot;counter&quot;))).expr(&quot;erster&quot;, Expr.first(Expr.field(&quot;counter&quot;))).end();
</code></pre>

<p>This expression language can also be used in queries:</p>

<pre><code class="java">            Query&lt;UncachedObject&gt; q = morphium.createQueryFor(UncachedObject.class);
        q.expr(Expr.gt(Expr.field(UncachedObject.Fields.counter), Expr.intExpr(50)));
        log.info(Utils.toJsonString(q.toQueryObject()));
        List&lt;UncachedObject&gt; lst = q.asList();
        assert (lst.size() == 50) : &quot;Size wrong: &quot; + lst.size();


        for (UncachedObject u : q.q().asList()) {
            u.setDval(Math.random() * 100);
            morphium.store(u);
        }

        q = q.q().expr(Expr.gt(Expr.field(UncachedObject.Fields.counter), Expr.field(UncachedObject.Fields.dval)));
        lst = q.asList();
</code></pre>

<p>Hint: if you use <code>Expr</code> in your code, it is probably a good idea to use <code>import static
    de.caluga.morphium.aggregation.Expr.*;</code> to make the code easier to read and understand. </p>

<h2 id="additional-information-sources">Additional information sources</h2>

<p>There are some places, you also might want to look at for additional information on mongodb or <em>Morphium</em>:</p>

<ul>
    <li>The mongodb <a href="https://docs.mongodb.com/manual/introduction/">manual</a>, especially the part about <a
            href="https://docs.mongodb.com/manual/core/aggregation-pipeline/#pipeline">aggregation pipelines</a></li>
    <li>The <a href="https://caluga.de">caluga blog</a>, there are some articles on how to use <em>Morphium</em> and
        related projects and examples. Also, this document itself is available <a
                href="https://boesebeck.name/v/2014/9/5/morphium_documentation?lang=en">there</a>.<sup><a
                class="footnote" href="#fn10-7368" id="fnr10-7368" title="see footnote">10</a></sup></li>
</ul>

<h2 id="code-examples">Code Examples</h2>

<h3 id="cache-synchronization">Cache Synchronization</h3>

<pre><code class="java"> Messaging msg = new Messaging(morphium, 100, true);
        msg.start();
        MessagingCacheSynchronizer cs = new MessagingCacheSynchronizer(msg, morphium);

        Query&lt;Msg&gt; q = morphium.createQueryFor(Msg.class);
        long cnt = q.countAll();
        assert (cnt == 0) : &quot;Already a message?!?! &quot; + cnt;

        cs.sendClearMessage(CachedObject.class, &quot;test&quot;);
        Thread.sleep(2000);
        TestUtils.waitForWrites(morphium,log);
        cnt = q.countAll();
        assert (cnt == 1) : &quot;there should be one msg, there are &quot; + cnt;
        msg.terminate();
        cs.detach();
</code></pre>

<h3 id="geo-spacial-search">Geo Spacial Search</h3>

<pre><code class="java">    @Test
    public void nearTest() throws Exception {
        morphium.dropCollection(Place.class);
        ArrayList&lt;Place&gt; toStore = new ArrayList&lt;Place&gt;();
    //        morphium.ensureIndicesFor(Place.class);
        for (int i = 0; i &lt; 1000; i++) {
            Place p = new Place();
            List&lt;Double&gt; pos = new ArrayList&lt;Double&gt;();
            pos.add((Math.random() * 180) - 90);
            pos.add((Math.random() * 180) - 90);
            p.setName(&quot;P&quot; + i);
            p.setPosition(pos);
            toStore.add(p);
        }
        morphium.storeList(toStore);
    
        Query&lt;Place&gt; q = morphium.createQueryFor(Place.class).f(&quot;position&quot;).near(0, 0, 10);
        long cnt = q.countAll();
        log.info(&quot;Found &quot; + cnt + &quot; places around 0,0 (10)&quot;);
        List&lt;Place&gt; lst = q.asList();
        for (Place p : lst) {
            log.info(&quot;Position: &quot; + p.getPosition().get(0) + &quot; / &quot; + p.getPosition().get(1));
        }
    }
    
    @Index(&quot;position:2d&quot;)
    @NoCache
    @WriteBuffer(false)
    @WriteSafety(level = SafetyLevel.MAJORITY)
    @DefaultReadPreference(ReadPreferenceLevel.PRIMARY)
    @Entity
    public static class Place {
        @Id
        private ObjectId id;
    
        public List&lt;Double&gt; position;
        public String name;
    
        public ObjectId getId() {
            return id;
        }
    
        public void setId(ObjectId id) {
            this.id = id;
        }
    
        public List&lt;Double&gt; getPosition() {
            return position;
        }
    
        public void setPosition(List&lt;Double&gt; position) {
            this.position = position;
        }
    
        public String getName() {
            return name;
        }
    
        public void setName(String name) {
            this.name = name;
        }
    }
</code></pre>

<h3 id="iterator">Iterator</h3>

<pre><code class="java">    @Test
    public void basicIteratorTest() throws Exception {
        createUncachedObjects(1000);
    
        Query&lt;UncachedObject&gt; qu = getUncachedObjectQuery();
        long start = System.currentTimeMillis();
        MorphiumIterator&lt;UncachedObject&gt; it = qu.asIterable(2);
        assert (it.hasNext());
        UncachedObject u = it.next();
        assert (u.getCounter() == 1);
        log.info(&quot;Got one: &quot; + u.getCounter() + &quot;  / &quot; + u.getValue());
        log.info(&quot;Current Buffersize: &quot; + it.getCurrentBufferSize());
        assert (it.getCurrentBufferSize() == 2);
    
        u = it.next();
        assert (u.getCounter() == 2);
        u = it.next();
        assert (u.getCounter() == 3);
        assert (it.getCount() == 1000);
        assert (it.getCursor() == 3);
    
        u = it.next();
        assert (u.getCounter() == 4);
        u = it.next();
        assert (u.getCounter() == 5);
    
        while (it.hasNext()) {
            u = it.next();
            log.info(&quot;Object: &quot; + u.getCounter());
        }
    
        assert (u.getCounter() == 1000);
        log.info(&quot;Took &quot; + (System.currentTimeMillis() - start) + &quot; ms&quot;);
    }
</code></pre>

<h3 id="asynchronous-read">Asynchronous Read</h3>

<pre><code class="java">      @Test
    public void asyncReadTest() throws Exception {
        asyncCall = false;
        createUncachedObjects(100);
        Query&lt;UncachedObject&gt; q = morphium.createQueryFor(UncachedObject.class);
        q = q.f(&quot;counter&quot;).lt(1000);
        q.asList(new AsyncOperationCallback&lt;UncachedObject&gt;() {
            @Override
            public void onOperationSucceeded(AsyncOperationType type, Query&lt;UncachedObject&gt; q, long duration, List&lt;UncachedObject&gt; result, UncachedObject entity, Object... param) {
                log.info(&quot;got read answer&quot;);
                assertNotNull(result); : &quot;Error&quot;;
                assert (result.size() == 100) : &quot;Error&quot;;
                asyncCall = true;
            }
    
            @Override
            public void onOperationError(AsyncOperationType type, Query&lt;UncachedObject&gt; q, long duration, String error, Throwable t, UncachedObject entity, Object... param) {
                assert false;
            }
        });
        waitForAsyncOperationToStart(1000000);
        int count = 0;
        while (q.getNumberOfPendingRequests() &gt; 0) {
            count++;
            assert (count &lt; 10);
            System.out.println(&quot;Still waiting...&quot;);
            Thread.sleep(1000);
        }
        assert (asyncCall);
    }
</code></pre>

<h3 id="asynchronous-write">Asynchronous Write</h3>

<pre><code class="java">    @Test
    public void asyncStoreTest() throws Exception {
      asyncCall = false;
      super.createCachedObjects(1000);
      TestUtils.waitForWrites(morphium,log);
      log.info(&quot;Uncached object preparation&quot;);
      super.createUncachedObjects(1000);
      TestUtils.waitForWrites(morphium,log);
      Query&lt;UncachedObject&gt; uc = morphium.createQueryFor(UncachedObject.class);
      uc = uc.f(&quot;counter&quot;).lt(100);
      morphium.delete(uc, new AsyncOperationCallback&lt;Query&lt;UncachedObject&gt;&gt;() {
          @Override
          public void onOperationSucceeded(AsyncOperationType type, Query&lt;Query&lt;UncachedObject&gt;&gt; q, long duration, List&lt;Query&lt;UncachedObject&gt;&gt; result, Query&lt;UncachedObject&gt; entity, Object... param) {
                    log.info(&quot;Objects deleted&quot;);
          }
        
      @Override
      public void onOperationError(AsyncOperationType type, Query&lt;Query&lt;UncachedObject&gt;&gt; q, long duration, String error, Throwable t, Query&lt;UncachedObject&gt; entity, Object... param) {
                assert false;
            }
     });
    
    uc = uc.q();
    uc.f(&quot;counter&quot;).mod(3, 2);
        morphium.set(uc, &quot;counter&quot;, 0, false, true, new AsyncOperationCallback&lt;UncachedObject&gt;() {
            @Override
            public void onOperationSucceeded(AsyncOperationType type, Query&lt;UncachedObject&gt; q, long duration, List&lt;UncachedObject&gt; result, UncachedObject entity, Object... param) {
                log.info(&quot;Objects updated&quot;);
                asyncCall = true;
    
            }
    
            @Override
            public void onOperationError(AsyncOperationType type, Query&lt;UncachedObject&gt; q, long duration, String error, Throwable t, UncachedObject entity, Object... param) {
                log.info(&quot;Objects update error&quot;);
            }
    });
    
    TestUtils.waitForWrites(morphium,log);
    
    assert(morphium.createQueryFor(UncachedObject.class).f(&quot;counter&quot;).eq(0).countAll() &gt; 0);
    assert (asyncCall);
}
</code></pre>

<h2 id="disclaimer">Disclaimer</h2>

<p>This document was written by the authors with most care, but there is no guarantee for 100% accuracy. If you have any
    questions, find a mistake or have suggestions for improvements, please contact the authors of this document and the
    developers of morphium via <a href="https://www.github.com/sboesebeck/morphium">github.com/sboesebeck/morphium</a>
    or send an email to <a href="mailto:sb@caluga.de">sb@caluga.de</a></p>

<div class="footnotes">
    <hr/>
    <ol>

        <li id="fn1-7368">
            <p>you can even use aggregation on it, to gather more information about your messages <a
                    class="reversefootnote" href="#fnr1-7368" title="return to article">&#8617;&#xFE0E;</a></p>
        </li>

        <li id="fn2-7368">
            <p>those throw an Exception to let you know, it is missing <a class="reversefootnote" href="#fnr2-7368"
                                                                          title="return to article">&#8617;&#xFE0E;</a>
            </p>
        </li>

        <li id="fn3-7368">
            <p>does only make sense, when there is more than one recipient usually <a class="reversefootnote"
                                                                                      href="#fnr3-7368"
                                                                                      title="return to article">&#8617;&#xFE0E;</a>
            </p>
        </li>

        <li id="fn4-7368">
            <p>attention: the &quot;top level&quot; document needs to be an Entity to have all necessary settings there.
                But &quot;subdocuments&quot;/properties might be just serializable <a class="reversefootnote"
                                                                                      href="#fnr4-7368"
                                                                                      title="return to article">&#8617;&#xFE0E;</a>
            </p>
        </li>

        <li id="fn5-7368">
            <p>text search and text indices can be disabled in mongoDB config. When creating the index, it would throw
                an Exception <a class="reversefootnote" href="#fnr5-7368" title="return to article">&#8617;&#xFE0E;</a>
            </p>
        </li>

        <li id="fn6-7368">
            <p>can be switched off in morphiumConfig <a class="reversefootnote" href="#fnr6-7368"
                                                        title="return to article">&#8617;&#xFE0E;</a></p>
        </li>

        <li id="fn7-7368">
            <p>as it takes some time for <em>Morphium</em> and mongo do determine if a cluster member is down, some
                requests might actually block <a class="reversefootnote" href="#fnr7-7368" title="return to article">&#8617;&#xFE0E;</a>
            </p>
        </li>

        <li id="fn8-7368">
            <p>also only works when connected to a replicaset <a class="reversefootnote" href="#fnr8-7368"
                                                                 title="return to article">&#8617;&#xFE0E;</a></p>
        </li>

        <li id="fn9-7368">
            <p>does not work with the `InMemoryDriver' yet <a class="reversefootnote" href="#fnr9-7368"
                                                              title="return to article">&#8617;&#xFE0E;</a></p>
        </li>

        <li id="fn10-7368">
            <p>this blog is powered by <em>Morphium</em> and mongodb <a class="reversefootnote" href="#fnr10-7368"
                                                                        title="return to article">&#8617;&#xFE0E;</a>
            </p>
        </li>

    </ol>
</div>

</body>
</html>
